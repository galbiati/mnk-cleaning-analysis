{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy as pt\n",
    "import pymc3 as pm\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from theano import tensor as T\n",
    "\n",
    "# Internal libraries\n",
    "sys.path.append('../../src')\n",
    "from lib.reconstruction.bayes.preprocessing.pivots import (load_tidy, \n",
    "                                                           compute_extra_tidy, \n",
    "                                                           compute_per_subject_pivot, \n",
    "                                                           compute_per_trial_pivot)\n",
    "from lib.reconstruction.features import count_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configuration\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "# os.environ['THEANO_FLAGS'] = 'device=cuda,floatX=float32'\n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')\n",
    "\n",
    "colors = sns.cubehelix_palette(n_colors=2, start=0.5, hue=1, rot=.1, light=.65) \n",
    "colors += sns.cubehelix_palette(n_colors=2, start=2.5, hue=1, rot=.1, light=.65)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df, board_set_df = load_tidy('../../etc/reconstruction/tidy_data.csv')\n",
    "\n",
    "# One position was duplicated between real/fake positions; drop it from data\n",
    "valid_ids = tidy_df.pivot_table(index='Position ID', values='Subject ID', aggfunc=len)\n",
    "valid_ids = valid_ids.loc[valid_ids['Subject ID'] == 38]\n",
    "valid_ids = valid_ids.index.tolist()\n",
    "tidy_df = tidy_df.loc[tidy_df['Position ID'].isin(valid_ids)]\n",
    "board_set_df = board_set_df.loc[valid_ids]\n",
    "board_set_df.sort_index(inplace=True)\n",
    "board_set_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "upids = tidy_df.sort_values('Position ID')['Position ID'].unique()\n",
    "pid_map = dict(zip(upids, np.arange(0, len(upids), 1, dtype=int)))\n",
    "tidy_df['Position ID'] = tidy_df['Position ID'].map(pid_map)\n",
    "\n",
    "extra_tidy_df = compute_extra_tidy(tidy_df)\n",
    "per_trial_df = compute_per_trial_pivot(extra_tidy_df)\n",
    "per_subject_df = compute_per_subject_pivot(per_trial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features\n",
    "all_features = tidy_df.apply(count_all_features, axis=1)\n",
    "feature_names = list(all_features.iloc[0].keys())\n",
    "feature_base_names = list(set([fn[:-1] for fn in feature_names]))\n",
    "\n",
    "for fn in feature_names:\n",
    "    extra_tidy_df[f'feature_{fn}'] = np.concatenate(all_features.map(lambda x: x[fn]).values)\n",
    "    \n",
    "for bn in feature_base_names:\n",
    "    b = np.concatenate(all_features.map(lambda x: x[f'{bn}b']).values)\n",
    "    w = b = np.concatenate(all_features.map(lambda x: x[f'{bn}w']).values)\n",
    "    extra_tidy_df[f'basef_{bn}'] = b + w\n",
    "    \n",
    "extra_tidy_df['same'] = extra_tidy_df['same'].astype(float)\n",
    "extra_tidy_df['opposite'] = extra_tidy_df['opposite'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_position_levels = len(extra_tidy_df.position_type.unique())\n",
    "num_condition_levels = len(extra_tidy_df.condition_indicator.unique())\n",
    "num_interaction_levels = num_position_levels * num_condition_levels\n",
    "num_subjects = len(extra_tidy_df.usubject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['n_pieces'] = extra_tidy_df.position_id.map(board_set_df['Num Pieces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "# formula = 'errors_2 ~ C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, per_trial_df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')\n",
    "endogenous_df = endogenous_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['successes_2'] = extra_tidy_df['occupied'] - extra_tidy_df['errors_2']\n",
    "# formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "formula = 'errors_2 ~ C(condition_indicator, Sum) * C(position_type, Sum) + n_pieces + same + opposite'\n",
    "\n",
    "# exogenous_df, endogenous_df = pt.dmatrices(formula, extra_tidy_df, \n",
    "#                                            return_type='dataframe', \n",
    "#                                            NA_action='raise')\n",
    "# endogenous_df = endogenous_df.astype(int)\n",
    "\n",
    "sm_model = sm.Logit.from_formula(formula, extra_tidy_df)\n",
    "result = sm_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['same'] = extra_tidy_df['same'].astype(float)\n",
    "extra_tidy_df['opposite'] = extra_tidy_df['opposite'].astype(float)\n",
    "\n",
    "# Important interactions:\n",
    "# 1. color and feature\n",
    "#    \"Should a heuristic function distinguish between feature colors?\"\n",
    "# 2. training and feature\n",
    "#    \"Does prior experience with the game bias subjects towards features from the game model?\"\n",
    "# 3. same and opposite\n",
    "#    \"Do different colors in context have a simple impact?\"\n",
    "# 4. training and num_pieces (and position type?)\n",
    "#    \"Does game experience provide a subject with a more efficient position encoding scheme?\"\n",
    "\n",
    "formula = 'errors_2 ~ C(condition_indicator) + C(condition_indicator, Sum) + C(position_type, Sum) + '\n",
    "formula += 'n_pieces + same + opposite + C(color, Sum) + '\n",
    "formula += ' + '.join(f'basef_{bn}' for bn in feature_base_names)\n",
    "\n",
    "# Interactions\n",
    "# formula += ' + ' + ' + '.join(f'basef_{bn}:C(color, Sum)' for bn in feature_base_names)\n",
    "# formula += ' + ' + ' + '.join(f'basef_{bn}:C(condition_indicator, Sum)' for bn in feature_base_names)\n",
    "# formula += ' + ' + 'C(condition_indicator, Sum):n_pieces'\n",
    "\n",
    "# old\n",
    "# Feature names including color\n",
    "# formula += ' + '.join(f'feature_{fn}' for fn in feature_names)\n",
    "\n",
    "\n",
    "df = extra_tidy_df.copy()\n",
    "df = df.loc[df['occupied'] == 1]\n",
    "# df['n_pieces'] = df.n_pieces - df.n_pieces.max() + .5 * (df.n_pieces.max() - df.n_pieces.min())\n",
    "# df['same'] = df.same - .5\n",
    "# df['opposite'] = df.opposite - .5\n",
    "\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')\n",
    "\n",
    "index_cols = ['Intercept', \n",
    "              'C(condition_indicator)[T.1]', \n",
    "              'C(position_type)[T.1]', \n",
    "              'C(condition_indicator)[T.0]:C(position_type)[T.0]']\n",
    "\n",
    "for c in index_cols:\n",
    "    if c in endogenous_df.columns:\n",
    "        endogenous_df[c] = endogenous_df[c].astype(int)\n",
    "    \n",
    "endogenous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coeff(name, shape=(2,), mu=0):\n",
    "#     sigma_prior = pm.Gamma(f'sigma_prior_{name}', 1.64, .32)\n",
    "#     sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#     a_prior = pm.Normal(f'a_prior_{name}', mu=mu, sigma=sigma, shape=shape)\n",
    "    \n",
    "    a = pm.Normal(f'a_{name}', mu=(0, 0), sigma=1, shape=shape)\n",
    "    return a\n",
    "\n",
    "\n",
    "condition = endogenous_df['C(condition_indicator)[T.1]'].values\n",
    "\n",
    "\n",
    "with pm.Model() as logistic_anova:\n",
    "    b0 = pm.Normal(f'intercept', mu=0, sigma=2)\n",
    "    \n",
    "    # Coefficients\n",
    "#     b_condition = create_coeff('condition')\n",
    "    b_condition = pm.Normal(f'a_condition', mu=0, sigma=2)\n",
    "    \n",
    "    # Position level\n",
    "    b_position = create_coeff('position')\n",
    "    b_n_pieces = create_coeff('n_pieces')\n",
    "    \n",
    "    # Piece level\n",
    "    b_color = create_coeff('color')\n",
    "    b_same = create_coeff('same')\n",
    "    b_opposite = create_coeff('opposite')\n",
    "    \n",
    "    b_f1101 = create_coeff('f1101')\n",
    "    b_f1001 = create_coeff('f1001')\n",
    "    b_f1111 = create_coeff('f1111')\n",
    "    b_f1010 = create_coeff('f1010')\n",
    "    b_f1100 = create_coeff('f1100')\n",
    "    b_f1110 = create_coeff('f1110')\n",
    "    \n",
    "    # Regression equation\n",
    "    mu = b0\n",
    "    mu += b_condition * endogenous_df['C(condition_indicator, Sum)[S.0]'].values\n",
    "    mu += b_position[condition] * endogenous_df['C(position_type, Sum)[S.0]'].values\n",
    "    mu += b_n_pieces[condition] * endogenous_df.n_pieces.values\n",
    "    mu += b_color[condition] * endogenous_df['C(color, Sum)[S.-1]'].values\n",
    "    mu += b_same[condition] * endogenous_df.same.values\n",
    "    mu += b_opposite[condition] * endogenous_df.opposite.values\n",
    "    mu += b_f1101[condition] * endogenous_df.basef_1101.values\n",
    "    mu += b_f1001[condition] * endogenous_df.basef_1001.values\n",
    "    mu += b_f1111[condition] * endogenous_df.basef_1111.values\n",
    "    mu += b_f1010[condition] * endogenous_df.basef_1010.values\n",
    "    mu += b_f1100[condition] * endogenous_df.basef_1100.values\n",
    "    mu += b_f1110[condition] * endogenous_df.basef_1110.values\n",
    "    \n",
    "    mu = pm.invlogit(mu)\n",
    "    \n",
    "    y = pm.Bernoulli('tagerts', p=mu, observed=exogenous_df['errors_2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    step = pm.NUTS(target_accept=.99, max_treedepth=10)\n",
    "    trace = pm.sample(2500, step, tune=2000, chains=6, cores=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.traceplot(trace, var_names=['intercept', 'a_condition', 'a_position', 'a_n_pieces'])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3), dpi=150)\n",
    "\n",
    "position = trace.get_values('a_condition')\n",
    "\n",
    "sns.distplot(position[:, 0] - position[:, 1], ax=axes[0])\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3), dpi=150)\n",
    "\n",
    "# var_names = ['intercept', 'a_position', 'a_condition', \n",
    "#              'a_num_pieces', 'a_interaction', 'a_same', 'a_color',\n",
    "#              'a_opposite', 'a_features']\n",
    "\n",
    "# var_names += [f'a_feature_{fn}' for fn in feature_names]\n",
    "\n",
    "var_names = ['intercept', 'a_condition', 'a_position']\n",
    "\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=var_names,\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0, round_to=3)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 9), dpi=150)\n",
    "\n",
    "# var_names = ['intercept', 'a_position', 'a_condition', \n",
    "#              'a_num_pieces', 'a_interaction', 'a_same', 'a_color',\n",
    "#              'a_opposite', 'a_features']\n",
    "\n",
    "# var_names += [f'a_feature_{fn}' for fn in feature_names]\n",
    "\n",
    "var_names = ['a_n_pieces', 'a_same', 'a_opposite', 'a_color',] # 'a_condition_x_n_pieces', 'a_same_x_opposite']\n",
    "\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=var_names,\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0, round_to=3)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(6, 3, figsize=(12, 18), dpi=150)\n",
    "\n",
    "var_names = [f'a_f{f}' for f in feature_base_names]\n",
    "\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=var_names,\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0, round_to=3)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
