{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# Numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy as pt\n",
    "import pymc3 as pm\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from theano import tensor as T\n",
    "\n",
    "# Internal libraries\n",
    "sys.path.append('../../src')\n",
    "from lib.reconstruction.bayes.preprocessing.pivots import (load_tidy, \n",
    "                                                           compute_extra_tidy, \n",
    "                                                           compute_per_subject_pivot, \n",
    "                                                           compute_per_trial_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configuration\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "# os.environ['THEANO_FLAGS'] = 'device=cuda,floatX=float32'\n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')\n",
    "\n",
    "colors = sns.cubehelix_palette(n_colors=2, start=0.5, hue=1, rot=.1, light=.65) \n",
    "colors += sns.cubehelix_palette(n_colors=2, start=2.5, hue=1, rot=.1, light=.65)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df, board_set_df = load_tidy('../../etc/reconstruction/tidy_data.csv')\n",
    "\n",
    "# One position was duplicated between real/fake positions; drop it from data\n",
    "valid_ids = tidy_df.pivot_table(index='Position ID', values='Subject ID', aggfunc=len)\n",
    "valid_ids = valid_ids.loc[valid_ids['Subject ID'] == 38]\n",
    "valid_ids = valid_ids.index.tolist()\n",
    "tidy_df = tidy_df.loc[tidy_df['Position ID'].isin(valid_ids)]\n",
    "board_set_df = board_set_df.loc[valid_ids]\n",
    "board_set_df.sort_index(inplace=True)\n",
    "board_set_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "upids = tidy_df.sort_values('Position ID')['Position ID'].unique()\n",
    "pid_map = dict(zip(upids, np.arange(0, len(upids), 1, dtype=int)))\n",
    "tidy_df['Position ID'] = tidy_df['Position ID'].map(pid_map)\n",
    "\n",
    "extra_tidy_df = compute_extra_tidy(tidy_df)\n",
    "per_trial_df = compute_per_trial_pivot(extra_tidy_df)\n",
    "per_subject_df = compute_per_subject_pivot(per_trial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_position_levels = len(extra_tidy_df.position_type.unique())\n",
    "num_condition_levels = len(extra_tidy_df.condition_indicator.unique())\n",
    "num_interaction_levels = num_position_levels * num_condition_levels\n",
    "num_subjects = len(extra_tidy_df.usubject.unique())\n",
    "\n",
    "def get_model_inputs(df, target_column, count_column):\n",
    "    y = df[target_column].values\n",
    "    n = df[count_column].values\n",
    "    \n",
    "    num_obs = len(y)\n",
    "\n",
    "    p_cat = df.position_type.astype('category').cat.codes.values\n",
    "    c_cat = df.condition_indicator.astype('category').cat.codes.values\n",
    "    i_cat = df.interaction.astype('category').cat.codes.values\n",
    "    s_cat = df.interaction.astype('category').cat.codes.values\n",
    "    \n",
    "    return y, n, num_obs, p_cat, c_cat, i_cat, s_cat\n",
    "    \n",
    "\n",
    "y, n, num_obs, p_cat, c_cat, i_cat, s_cat = get_model_inputs(per_subject_df, \n",
    "                                                             'errors_2', \n",
    "                                                             'occupied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['n_pieces'] = extra_tidy_df.position_id.map(board_set_df['Num Pieces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "# formula = 'errors_2 ~ C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, per_trial_df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')\n",
    "endogenous_df = endogenous_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['successes_2'] = extra_tidy_df['occupied'] - extra_tidy_df['errors_2']\n",
    "# formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "formula = 'errors_2 ~ C(condition_indicator, Sum) * C(position_type, Sum) + n_pieces * same * opposite'\n",
    "\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, extra_tidy_df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')\n",
    "endogenous_df = endogenous_df.astype(int)\n",
    "\n",
    "# sm_model = sm.GLM(endogenous_df, extra_tidy_df[['successes_2', 'errors_2']], \n",
    "#                   family=Bernoulli())\n",
    "\n",
    "sm_model = sm.Logit.from_formula(formula, extra_tidy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_coeff(name, shape):\n",
    "#     sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#     a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=(shape - 1))\n",
    "#     a_last = \n",
    "#     return a\n",
    "y, n, num_obs, p_cat, c_cat, i_cat, s_cat = get_model_inputs(per_subject_df, \n",
    "                                                             'errors_2', \n",
    "                                                             'occupied')\n",
    "\n",
    "\n",
    "def create_coeff(name, shape=1):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    dummy = pm.Normal(f'dummy_{name}', mu=0, sd=1, shape=shape)\n",
    "    a = pm.Deterministic(f'a_{name}', dummy * sigma)\n",
    "#     a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "#     if shape > 1:\n",
    "#         a = T.concatenate([a, -a.sum(keepdims=True)])\n",
    "#     else:\n",
    "#         a = T.stack([a, -a.sum(keepdims=True)])\n",
    "#     a = pm.Deterministic(f'a_{name}', a)\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "    \n",
    "    a_position = create_coeff('position', shape=2)\n",
    "    a_condition = create_coeff('condition', shape=2)\n",
    "    a_interaction = create_coeff('interaction', shape=(2, 2))\n",
    "    \n",
    "    # Interaction requires two-way correction, so skip for now\n",
    "    \n",
    "    # TODO: for now, leave subjects as just subtracting the last\n",
    "    #       later, subtract last from each *group* of subjects\n",
    "    #       I *think* that will force variance onto group parameters?\n",
    "    \n",
    "    a_subject = create_coeff('subject', shape=num_subjects)\n",
    "\n",
    "    mu = a0\n",
    "    mu += a_position[p_cat]\n",
    "    mu += a_condition[c_cat]\n",
    "    mu += a_interaction[c_cat, p_cat]\n",
    "    mu += a_subject[s_cat]\n",
    "    mu = pm.Deterministic('mu', mu.squeeze())\n",
    "\n",
    "    omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "    kappa = pm.Gamma('beta_variance', .01, .01)#mu=1, sigma=10)\n",
    "    alpha = omega * (kappa - 2) + 1\n",
    "    beta = (1 - omega) * (kappa - 2) + 1\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=num_obs)\n",
    "    y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "    \n",
    "#     # Sum-to-zero:\n",
    "#     m_position = a0 + a_position\n",
    "#     m_condition = a0 + a_condition\n",
    "    \n",
    "#     b0 = m_position.sum() + m_condition.sum()\n",
    "#     b0 /= num_position_levels + num_condition_levels\n",
    "#     b0 = pm.Deterministic('b0', b0)\n",
    "#     b_position = pm.Deterministic('b_position', m_position - b0)\n",
    "#     b_condition = pm.Deterministic('b_condition', m_condition - b0)\n",
    "\n",
    "#     a = T.concatenate([a_position, a_condition, a_interaction, a_subject])\n",
    "#     m = pm.Deterministic('m', a0 + a)\n",
    "#     bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "#     bb = pm.Deterministic('bb', m - bb0)\n",
    "\n",
    "#     position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "#     condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # Initialize starting point from MLE values\n",
    "#     start = {'intercept': (-2.2, ), 'a_condition': (.07, ), 'a_position': (.21, )}\n",
    "    step = pm.NUTS(target_accept=.999, max_treedepth=15)\n",
    "    trace = pm.sample(8000, step, tune=8000, chains=8, cores=8) #, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.traceplot(trace, var_names=['a_position',])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(16, 8), dpi=150)\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=['intercept', 'a_condition', 'a_position'],\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = trace['intercept']\n",
    "t_position = trace['a_position']\n",
    "t_condition = trace['a_condition']\n",
    "t_subject = trace['a_subject']\n",
    "\n",
    "m = np.zeros((num_subjects, num_condition_levels, num_position_levels, len(t_position)))\n",
    "\n",
    "for k, i, j in zip(s_cat, c_cat, p_cat):\n",
    "    mu = t0 + t_condition[:, i] + t_position[:, j] + t_subject[:, k]\n",
    "    m[k, i, j, :] = mu\n",
    "    \n",
    "m_ma = ma.masked_equal(m, 0)\n",
    "m_subject = m_ma.mean(axis=2, keepdims=True)\n",
    "m_interaction = m_ma.mean(axis=0)\n",
    "m_condition = m_interaction.mean(axis=1, keepdims=True)\n",
    "m_position = m_interaction.mean(axis=0, keepdims=True)\n",
    "\n",
    "b0 = m_interaction.mean(axis=(0, 1))\n",
    "b_condition = m_condition.squeeze() - b0\n",
    "b_position = m_position.squeeze() - b0\n",
    "b_interaction = m_interaction - m_condition - m_position + b0\n",
    "b_subject = m_subject - m_condition.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_df.values.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tidy_df['same'] = extra_tidy_df['same'].astype(float)\n",
    "extra_tidy_df['opposite'] = extra_tidy_df['opposite'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'errors_2 ~ C(condition_indicator, Sum) * C(position_type, Sum) + n_pieces * same * opposite'\n",
    "\n",
    "df = extra_tidy_df.copy()\n",
    "df['n_pieces'] = df.n_pieces - df.n_pieces.max() + .5 * (df.n_pieces.max() - df.n_pieces.min())\n",
    "df['same'] = df.same - .5\n",
    "df['opposite'] = df.opposite - .5\n",
    "\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['Intercept', \n",
    "              'C(condition_indicator, Sum)[S.0]', \n",
    "              'C(position_type, Sum)[S.0]', \n",
    "              'C(condition_indicator, Sum)[S.0]:C(position_type, Sum)[S.0]']\n",
    "for c in index_cols:\n",
    "    endogenous_df[c] = endogenous_df[c].astype(int)\n",
    "    \n",
    "endogenous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_coeff(name, shape, mu=None):\n",
    "#     if mu is None:\n",
    "#         # Group prior on coefficient variance\n",
    "#         sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#         # Group prior on coefficient mean\n",
    "#         mu = pm.Normal(f'mu_{name}', mu=0, tau=1/sigma**2)\n",
    "    \n",
    "#     # Coefficient samples\n",
    "#     a = pm.Normal(f'a_{name}', mu=mu, sd=.1, shape=shape)\n",
    "#     return a\n",
    "\n",
    "\n",
    "# Organize coefficients as {<col name>: {shape: <shape>, name: <coeff name>}} or similar for easier use\n",
    "def create_coeff(name, shape, mu=0):\n",
    "    a = pm.Normal(f'a_{name}', mu=mu, sigma=1, shape=shape)\n",
    "    return a\n",
    "\n",
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.Normal('intercept', mu=0, sd=1, shape=[1])\n",
    "    b_condition = create_coeff('condition', 1)\n",
    "    b_position = create_coeff('position', 1)\n",
    "    b_interaction = create_coeff('interaction', 1)\n",
    "#     b_subject = create_coeff('subject', endogenous_df.shape[1] - 4)\n",
    "    \n",
    "    b_num_pieces = create_coeff('num_pieces', 1)\n",
    "    b_occupied_same = create_coeff('same', 1)\n",
    "    b_occupied_opposite = create_coeff('opposite', 1)\n",
    "    b_n_x_same = create_coeff('n_x_same', 1)\n",
    "    b_n_x_opposite = create_coeff('n_x_opposite', 1)\n",
    "    b_same_x_opposite = create_coeff('same_x_opposite', 1)\n",
    "    b_n_x_same_x_opposite = create_coeff('n_x_same_x_opposite', 1)\n",
    "#     b = T.concatenate([b_subject, b_condition, b_position, b_interaction])\n",
    "#     b = T.concatenate([b_condition, b_position, b_interaction])\n",
    "#     b = T.concatenate([b_subject, b_condition, b_position])\n",
    "\n",
    "    # Estimate mean of beta prior as sigmoid\n",
    "#     mu = pm.invlogit(b0 + T.dot(endogenous_df.values[:, -3:], b))\n",
    "    v_condition = endogenous_df['C(condition_indicator, Sum)[S.0]'].values\n",
    "    v_position = endogenous_df['C(position_type, Sum)[S.0]'].values\n",
    "    v_interaction = endogenous_df['C(condition_indicator, Sum)[S.0]:C(position_type, Sum)[S.0]'].values\n",
    "    v_num_pieces = endogenous_df['n_pieces'].values\n",
    "    v_occupied_same = endogenous_df['same'].values\n",
    "    v_occupied_opposite = endogenous_df['opposite'].values\n",
    "    v_n_x_same = endogenous_df['n_pieces:same'].values\n",
    "    v_n_x_opposite = endogenous_df['n_pieces:opposite']\n",
    "    v_same_x_opposite = endogenous_df['same:opposite']\n",
    "    v_n_x_same_x_opposite = endogenous_df['n_pieces:same:opposite']\n",
    "\n",
    "    mu = b0\n",
    "    mu += b_condition * v_condition \n",
    "    mu += b_position * v_position\n",
    "    mu += b_interaction * v_interaction\n",
    "    mu += b_num_pieces * v_num_pieces\n",
    "    mu += b_occupied_same * v_occupied_same\n",
    "    mu += b_occupied_opposite * v_occupied_opposite\n",
    "    mu += b_n_x_same * v_n_x_same\n",
    "    mu += b_n_x_opposite * v_n_x_opposite\n",
    "    mu += b_same_x_opposite * v_same_x_opposite\n",
    "    mu += b_n_x_same_x_opposite * v_n_x_same_x_opposite\n",
    "    \n",
    "#     for i, c in enumerate(endogenous_df.columns[1:-3]):\n",
    "#         v_subject = endogenous_df[c].values\n",
    "#         mu += b_subject[i] * v_subject\n",
    "        \n",
    "    mu = pm.invlogit(mu)\n",
    "#     kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "#     alpha = mu * (kappa - 2) + 1\n",
    "#     beta = (1 - mu) * (kappa - 2) + 1\n",
    "\n",
    "#     theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=exogenous_df.shape[0])\n",
    "    \n",
    "    # Likelihood\n",
    "#     y = pm.Binomial('targets', n=df['occupied'].values, p=mu,\n",
    "#                     observed=exogenous_df['errors_2'].values)\n",
    "    y = pm.Bernoulli('targets', p=mu, observed=exogenous_df['errors_2'].values)\n",
    "    \n",
    "    # Contrasts\n",
    "    \n",
    "    #   Within-group subject correction\n",
    "    #     Compute full subject coefficients\n",
    "#     s = T.concatenate([b_subject, -T.sum(b_subject, keepdims=True)])\n",
    "#     #     Reshape to have subject coeffs grouped by condition\n",
    "#     s = s.reshape((2, -1))\n",
    "#     b_condition_0 = b_condition + T.mean(s[0, :])\n",
    "#     #    Other condition is - first condtion, but still adjust updward by mean subject effect\n",
    "#     b_condition_1 = -b_condition + T.mean(s[1, :])\n",
    "    \n",
    "#     b_subject_ = pm.Deterministic('b_subject_m', \n",
    "#                                   (s - s.mean(axis=1, keepdims=True)).reshape((-1, )))\n",
    "    \n",
    "#     c_condition = pm.Deterministic('c_condition', 2 * b_condition) #b_condition_0 - b_condition_1)\n",
    "#     c_position = pm.Deterministic('c_position', 2 * b_position)\n",
    "#     c_interaction = pm.Deterministic('c_interaction', 4 * b_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    # Initialize starting point from MLE values\n",
    "#     start = {'intercept': (-2.2, ), 'a_condition': (.07, ), 'a_position': (.21, )}\n",
    "    step = pm.NUTS(target_accept=.98, max_treedepth=10)\n",
    "#     step = pm.NUTS()\n",
    "    trace = pm.sample(1000, step, tune=500, chains=8, cores=8) #, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with logistic_anova:\n",
    "#     svgd_approx = pm.fit(300, method='svgd', inf_kwargs=dict(n_particles=100),\n",
    "#                          obj_optimizer=pm.sgd(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.traceplot(trace, var_names=['a_position', 'a_condition', 'a_num_pieces'])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(16, 15), dpi=150)\n",
    "\n",
    "var_names = ['intercept', 'a_position', 'a_condition', \n",
    "             'a_num_pieces', 'a_interaction', 'a_same', \n",
    "             'a_opposite', 'a_n_x_same', 'a_n_x_opposite', \n",
    "             'a_same_x_opposite', 'a_n_x_same_x_opposite']\n",
    "\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=var_names,\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0, round_to=3)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(.08) / (1 + np.exp(.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) + C(position_type, Sum)'\n",
    "\n",
    "df = per_subject_df\n",
    "\n",
    "exogenous_df, endogenous_df = pt.dmatrices(formula, df, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')\n",
    "endogenous_df = endogenous_df.astype(int)\n",
    "\n",
    "# def create_coeff(name, shape, mu=None):\n",
    "#     if mu is None:\n",
    "#         # Group prior on coefficient variance\n",
    "#         sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#         # Group prior on coefficient mean\n",
    "#         mu = pm.Normal(f'mu_{name}', mu=0, tau=1/sigma**2)\n",
    "    \n",
    "#     # Coefficient samples\n",
    "#     a = pm.Normal(f'a_{name}', mu=mu, sd=.1, shape=shape)\n",
    "#     return a\n",
    "\n",
    "def create_coeff(name, shape, mu=0):\n",
    "#     sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    sigma = pm.Gamma(f'sigma_{name}', .01, .01)\n",
    "    a = pm.Normal(f'a_{name}', mu=mu, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.Normal('intercept', mu=0, sd=1, shape=[1])\n",
    "    b_condition = create_coeff('condition', 1)\n",
    "    b_position = create_coeff('position', 1)\n",
    "#     b_interaction = create_coeff('interaction', 1)\n",
    "    b_subject = create_coeff('subject', endogenous_df.shape[1] - 3)\n",
    "#     b = T.concatenate([b_subject, b_condition, b_position, b_interaction])\n",
    "    b = T.concatenate([b_subject, b_condition, b_position])\n",
    "\n",
    "    # Estimate mean of beta prior as sigmoid\n",
    "    mu = T.nnet.sigmoid(b0 + T.dot(endogenous_df.values[:, 1:], b))\n",
    "    kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "    alpha = mu * (kappa - 2) + 1\n",
    "    beta = (1 - mu) * (kappa - 2) + 1\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=exogenous_df.shape[0])\n",
    "    \n",
    "    # Likelihood\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=df['occupied'].values,\n",
    "                    p=theta,\n",
    "                    observed=exogenous_df['errors_2'].values)\n",
    "    \n",
    "    # Contrasts\n",
    "    \n",
    "    #   Within-group subject correction\n",
    "    #     Compute full subject coefficients\n",
    "    s = T.concatenate([b_subject, -T.sum(b_subject, keepdims=True)])\n",
    "    #     Reshape to have subject coeffs grouped by condition\n",
    "    s = s.reshape((2, -1))\n",
    "    b_condition_0 = b_condition + T.mean(s[0, :])\n",
    "    #    Other condition is - first condtion, but still adjust updward by mean subject effect\n",
    "    b_condition_1 = -b_condition + T.mean(s[1, :])\n",
    "    \n",
    "    b_subject_ = pm.Deterministic('b_subject_m', \n",
    "                                  (s - s.mean(axis=1, keepdims=True)).reshape((-1, )))\n",
    "    \n",
    "    c_condition = pm.Deterministic('c_condition', b_condition_0 - b_condition_1)\n",
    "    c_position = pm.Deterministic('c_position', 2 * b_position)\n",
    "#     c_interaction = pm.Deterministic('c_interaction', 4 * b_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    # Initialize starting point from MLE values\n",
    "#     start = {'intercept': (-2.2, ), 'a_condition': (.07, ), 'a_position': (.21, )}\n",
    "    step = pm.NUTS(target_accept=.999, max_treedepth=15)\n",
    "    trace = pm.sample(8000, step, tune=8000, chains=8, cores=8) #, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace, var_names=['a_position',])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), dpi=150)\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=['intercept', 'a_condition', 'a_position'],\n",
    "                  color='#87ceeb', kind='hist', ax=axes,\n",
    "                  rope=(-.01, .01), ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No condition split-plot BANOVA design\n",
    "# TODO:\n",
    "# This needs to only have coefficients for subject and position type\n",
    "# Then a deterministic var that computes \n",
    "# mean(subjects[trained]) - mean(subjects[untrained])\n",
    "\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=num_subjects)\n",
    "        y = pm.Binomial('targets', p=theta[subject_index], n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction, a_subject])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No subject split-plot BANOVA design\n",
    "# In standard BANOVA, when each subject belongs to only one condition,\n",
    "# condition and subject are in a sense confounded\n",
    "\n",
    "# That is, all variability due to condition \n",
    "# could be capture in the subject coefficients\n",
    "\n",
    "# This modification of ANOVA treats subjects as noise instead,\n",
    "# with a shared logistic prior \n",
    "# that only includes condition, position type, and interaction\n",
    "\n",
    "# I suppose one further alternative is to do some post processing on\n",
    "# sampled values: for each condition coefficient, \n",
    "# add the mean of all of that condition's subjects' coefficients\n",
    "# and subtract that mean from all that condition's subjects' coefficients\n",
    "\n",
    "# This will \"correct\" the estimated condition coefficients \n",
    "# to contain *all* the variance from subjects within that condition\n",
    "\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coeff(name, shape, sigma=None):\n",
    "    if sigma is None:\n",
    "#         sigma = pm.HalfStudentT(f'sigma_{name}', nu=2, lam=.1)\n",
    "          sigma = pm.Gamma(f'sigma', 1.64, .32)\n",
    "#     noise = pm.Normal(f'noise_{name}', mu=0, sd=1, shape=shape)\n",
    "#     a = pm.Deterministic(f'a_{name}', noise * sigma)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        sigma = pm.Gamma(f'sigma', 1.64, .32)\n",
    "        \n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        a_subject = create_coeff('subject', num_subjects)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu += a_subject[subject_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "        kappa = pm.Gamma('beta_variance', .1, .1)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "#         a = T.concatenate([a_position, a_condition, a_interaction])\n",
    "#         m = pm.Deterministic('m', a0 + a)\n",
    "#         bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "#         bb = pm.Deterministic('bb', m - bb0)\n",
    "\n",
    "        # Reparameterize as deflections\n",
    "        # First, correct condition by subjects\n",
    "        \n",
    "        # Get the mean per group of subjects\n",
    "        a_sub_x_cond = a_subject.reshape((-1, 2))\n",
    "        m_sub_x_cond = T.mean(a_sub_x_cond, axis=0) # shape: (1, 2)\n",
    "        \n",
    "        # Add it to conditions and subtract it from subjects\n",
    "        b_condition_ = pm.Deterministic('b_condition_', a_condition + m_sub_x_cond)\n",
    "        b_subject_ = a_sub_x_cond - m_sub_x_cond\n",
    "        b_subject_ = pm.Deterministic('b_subject_', b_subject_.reshape((-1, )))\n",
    "    \n",
    "        m_position = T.mean(a_position)\n",
    "        m_condition = T.mean(b_condition_)\n",
    "        m_subject = T.mean(b_subject_)\n",
    "        m_interaction = T.mean(a_interaction)\n",
    "\n",
    "        b_position = pm.Deterministic('b_position', a_position - m_position)        \n",
    "        b_condition = pm.Deterministic('b_condition', b_condition_ - m_condition)\n",
    "        b_interaction = pm.Deterministic('b_interaction', a_interaction - m_interaction)\n",
    "        b_subject = pm.Deterministic('b_subject', b_subject_ - m_subject)\n",
    "        b0 = pm.Deterministic('b_intercept', \n",
    "                              a0 + m_position + m_condition + m_interaction + m_subject)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('contrast_position', \n",
    "                                             b_position[1] - b_position[0])\n",
    "        condition_contrast = pm.Deterministic('contrast_condition', \n",
    "                                              b_condition[1] - b_condition[0])\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Last edited 2019.09.14 8am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BANOVAModel(object):\n",
    "    def __init__(self, batch_size):\n",
    "        self.model = pm.Model()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def create_coefficient(self, name, shape, sigma=None):\n",
    "        if sigma is None:\n",
    "            sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "\n",
    "        a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "        return a\n",
    "    \n",
    "    def create_likelihood(self, omega, n, y):\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=self.batch_size)\n",
    "        \n",
    "        targets = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def create_model(self, position_index, interaction_index, subject_index, n, y):\n",
    "        with self.model:\n",
    "            a_s = self.create_coefficient('subject', self.num_subjects)\n",
    "            a_p = self.create_coefficient('position', self.num_position_levels)\n",
    "            a_i = self.create_coefficient('interaction', self.num_interaction_levels)\n",
    "            \n",
    "            mu = a_position[position_index]\n",
    "            mu += a_interaction[interaction_index]\n",
    "            mu += a_subject[subject_index]\n",
    "            mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "            omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "            \n",
    "            targets = self.create_likelihood(omega, n, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coeff(name, shape, sigma=None):\n",
    "    if sigma is None:\n",
    "        sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "        \n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    # Model without explicit condition or intercept\n",
    "    with pm.Model() as model: \n",
    "        # Coefficients with independent priors on variance\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "#         a_subject = create_coeff('subject', num_subjects)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        \n",
    "        # Regression equation\n",
    "        mu = a_position[position_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "#         mu += a_subject[subject_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "        \n",
    "        # Convert to beta parameters\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        # Sample probabilities and targets\n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        # Reparameterize as deflections\n",
    "        # First, correct condition by subjects\n",
    "        \n",
    "        # Get the mean per group of subjects\n",
    "#         a_sub_x_cond = a_subject.reshape((-1, 2))\n",
    "#         m_sub_x_cond = T.mean(a_sub_x_cond, axis=0) # shape: (1, 2)\n",
    "        \n",
    "        # Add it to conditions and subtract it from subjects\n",
    "#         b_condition_ = pm.Deterministic('b_condition_', a_condition + m_sub_x_cond)\n",
    "#         a_condition = pm.Deterministic('a_condition', m_sub_x_cond)\n",
    "#         a_subject_ = a_sub_x_cond - m_sub_x_cond\n",
    "#         a_subject_ = pm.Deterministic('a_subject_minus_condition', \n",
    "#                                       a_subject_.reshape((-1, )))\n",
    "    \n",
    "        m_position = T.mean(a_position)\n",
    "        m_condition = T.mean(a_condition)\n",
    "#         m_subject = T.mean(a_subject_)\n",
    "        m_interaction = T.mean(a_interaction)\n",
    "        \n",
    "        b_intercept = pm.Deterministic('b_intercept', \n",
    "                                       pm.logit(m_condition + m_position + m_interaction))\n",
    "        \n",
    "#         b_subject = pm.Deterministic('b_subject', a_subject_ - m_subject)\n",
    "        b_position = pm.Deterministic('b_position', pm.logit(a_position - m_position))   \n",
    "        b_condition = pm.Deterministic('b_condition', pm.logit(a_condition - m_condition))\n",
    "        b_interaction = pm.Deterministic('b_interaction', pm.logit(a_interaction - m_interaction))\n",
    "        \n",
    "        position_contrast = pm.Deterministic('contrast_position', \n",
    "                                             b_position[1] - b_position[0])\n",
    "        condition_contrast = pm.Deterministic('contrast_condition', \n",
    "                                              b_condition[1] - b_condition[0])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(p2e, c2e, i2e, s2e, y, n, batch_size,\n",
    "                     num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                     num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS(target_accept=.99, max_treedepth=15)\n",
    "    trace = pm.sample(4000, step, tune=6000, chains=8, cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "# pm.traceplot(trace, var_names=('b_intercept', 'b_position', 'b_condition', 'b_interaction'), )\n",
    "pm.traceplot(trace, \n",
    "             var_names=('sigma_condition', 'sigma_position')\n",
    "#              var_names=('sigma', )\n",
    "            )\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=('b_intercept', 'b_condition', 'b_interaction',\n",
    "                             'contrast_position', 'contrast_condition'),\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard split-plot BANOVA design\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#     sigma = pm.HalfSTudentT(f'sigma_{})\n",
    "#     sigma = pm.HalfStudentT(f'sigma_{name}', lam=.001, nu=1,) + .1\n",
    "#     noise = pm.Normal(f'noise_{name}', mu=0, sd=1, shape=shape)\n",
    "#     a = pm.Deterministic(f'a_{name}', noise * (sigma + .01))\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        \n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        a_subject = create_coeff('subject', num_subjects)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu += a_subject[subject_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        \n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction, a_subject])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(p2e, c2e, i2e, s2e, y, n, batch_size,\n",
    "                     num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                     num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS(target_accept=.99, max_treedepth=15)\n",
    "    trace = pm.sample(8000, step, tune=8000, chains=8, cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  varnames=['bb_pos', 'bb_con'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_dummies = pd.DataFrame(index=per_board_pivot.index, \n",
    "                                 data=np.ones(len(per_board_pivot)))\n",
    "position_dummies = pd.get_dummies(per_board_pivot.position_type)\n",
    "condition_dummies = pd.get_dummies(per_board_pivot.condition_indicator)\n",
    "interaction_dummies = pd.get_dummies(per_board_pivot.interaction)\n",
    "\n",
    "subject_dummies = pd.get_dummies(per_board_pivot.usubject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies = pd.concat([\n",
    "    intercept_dummies, \n",
    "    position_dummies, \n",
    "    condition_dummies, \n",
    "    interaction_dummies,\n",
    "    subject_dummies\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noncentered_coeffs(name, shape):\n",
    "    sd = pm.HalfStudentT(f'{name}_sd', nu=4, sigma=2.5, shape=shape)\n",
    "#     noise = pm.Normal(f'{name}_noise', mu=0, sd=1)\n",
    "#     a = pm.Deterministic(f'{name}_a', noise * sd)\n",
    "    a = pm.Normal(f'{name}_a', mu=0, sd=sd, shape=shape)\n",
    "    b = a - a.mean()\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def create_model(x, y, n, batch_size,\n",
    "                 num_subjects,\n",
    "                 num_position_levels, \n",
    "                 num_condition_levels): \n",
    "    \n",
    "    num_interaction_levels = num_position_levels * num_condition_levels\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # Create intercept coefficient; no prior on variance\n",
    "        b0 = pm.StudentT('intercept', mu=0, nu=2, lam=.001, shape=[1])\n",
    "        a_position, b_position = get_noncentered_coeffs('position', [num_position_levels])\n",
    "        a_condition, b_condition = get_noncentered_coeffs('condition', [num_condition_levels])\n",
    "        _, b_interaction = get_noncentered_coeffs('interaction', [num_interaction_levels])\n",
    "        _, b_subject = get_noncentered_coeffs('subject', [num_subjects])\n",
    "\n",
    "        coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "        coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "\n",
    "        mu = T.nnet.sigmoid(T.dot(x, coeffs))\n",
    "\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = mu * kappa\n",
    "        beta = (1 - mu) * kappa\n",
    "\n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', n=n, p=theta, observed=y)\n",
    "\n",
    "        # Contrasts\n",
    "        position_contrast = pm.Deterministic('position_contrast', \n",
    "                                             a_position[1] - a_position[0])\n",
    "        condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                              a_condition[1] - a_condition[0])\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_2e_model(position_index, condition_index, subject_index, num_obs,\n",
    "                    y, n,\n",
    "                    num_subjects, num_position_levels, num_condition_levels):\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # Hyper parameters\n",
    "        a_sigma = pm.Gamma('aSigma', 1.64, 0.32, shape=2)\n",
    "        \n",
    "        # Intercept\n",
    "        a0 = pm.Normal('a0', 0.0, tau=1/2**2)\n",
    "        \n",
    "        # Parameters\n",
    "        a_position = pm.Normal('a_position', 0.0, tau=1/a_sigma[0]**2, \n",
    "                               shape=[1, num_position_levels]) \n",
    "        a_condition = pm.Normal('a_condition', 0.0,  tau=1/a_sigma[1]**2,\n",
    "                                shape=[num_condition_levels, 1])\n",
    "        \n",
    "        # Parameters for categories (Primary field positions)\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(a0 + a_position + a_condition))\n",
    "        kappa = pm.Gamma('kappa', 0.01, 0.01)\n",
    "\n",
    "        # Parameter for individual players\n",
    "        theta_a = omega[position_index, condition_index] * kappa + 1\n",
    "        theta_b = (1 - omega[position_index, condition_index]) * kappa + 1\n",
    "        theta = pm.Beta('theta', theta_a, theta_b, shape=[num_subjects, num_obs])\n",
    "\n",
    "        y = pm.Binomial('y', n=n, p=theta[:, subject_index], observed=y)\n",
    "\n",
    "        # Convert a0,a to sum-to-zero b0,b \n",
    "        m = pm.Deterministic('m', a0 + a_position + a_condition)\n",
    "        b0 = pm.Deterministic('b0', T.mean(m))\n",
    "        b = pm.Deterministic('b', m - b0) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodp_model(position_index, condition_index, subject_index, \n",
    "                      y, n, batch_size,\n",
    "                      num_subjects, num_position_levels, num_condition_levels): \n",
    "    \n",
    "    num_interaction_levels = num_position_levels * num_condition_levels\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        b0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        \n",
    "        sigma_position = pm.Gamma('sigma_position', 1.64, 0.32)\n",
    "        noise_position = pm.Normal('noise_position', mu=0, sd=1, \n",
    "                                   shape=num_position_levels)\n",
    "        a_position = pm.Deterministic('a_position', \n",
    "                                      noise_position * 1/sigma_position**2)\n",
    "#         a_position = pm.Normal('a_position', mu=0, tau=1/sigma_position**2, \n",
    "#                                shape=num_position_levels)\n",
    "        \n",
    "        sigma_condition = pm.Gamma('sigma_condition', 1.64, 0.32)\n",
    "        noise_condition = pm.Normal('noise_condition', mu=0, sd=1,\n",
    "                                    shape=num_condition_levels)\n",
    "        a_condition = pm.Deterministic('a_condition',\n",
    "                                       noise_condition * 1/sigma_position**2)\n",
    "#         a_condition = pm.Normal('a_condition', mu=0, tau=1/sigma_condition**2, \n",
    "#                                 shape=num_condition_levels)\n",
    "        \n",
    "        sigma_subject = pm.Gamma('sigma_subject', 1.64, 0.32)\n",
    "        noise_subject = pm.Normal('noise_subject', mu=0, sd=1,\n",
    "                                  shape=num_subjects)\n",
    "        a_subject = pm.Deterministic('a_subject',\n",
    "                                     noise_subject * 1/sigma_subject**2)\n",
    "        \n",
    "#         a_subject = pm.Normal('a_subject', mu=0, tau=1/sigma_subject**2,\n",
    "#                               shape=num_subjects)\n",
    "\n",
    "        b_position = a_position - a_position.mean()\n",
    "        b_condition = a_condition - a_condition.mean()\n",
    "        b_subject = a_subject - a_subject.mean()\n",
    "        \n",
    "        mu = b0\n",
    "        mu += b_position[position_index]\n",
    "        mu += b_condition[condition_index]\n",
    "        mu += b_subject[subject_index]\n",
    "        \n",
    "#         mu = T.nnet.sigmoid(mu)\n",
    "#         mu = pm.Deterministic('mu', T.nnet.sigmoid(mu))\n",
    "        mu = pm.Deterministic('mu', pm.invlogit(mu))\n",
    "        \n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = mu * kappa\n",
    "        beta = (1 - mu) * kappa\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', n=n, p=theta, observed=y)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('position_contrast', \n",
    "                                             a_position[1] - a_position[0])\n",
    "        condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                              a_condition[1] - a_condition[0])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_dummies.values\n",
    "n = per_board_pivot['occupied'].values\n",
    "y = per_board_pivot['errors_2'].values\n",
    "\n",
    "num_obs = x.shape[0]\n",
    "\n",
    "# batch_size = 128\n",
    "batch_size = num_obs\n",
    "\n",
    "x_batches = pm.Minibatch(x, batch_size=batch_size)\n",
    "n_batches = pm.Minibatch(n, batch_size=batch_size)\n",
    "y_batches = pm.Minibatch(y, batch_size=batch_size)\n",
    "\n",
    "num_subjects = len(subject_dummies.columns)\n",
    "num_position_levels = 2\n",
    "num_condition_levels = 2\n",
    "\n",
    "# anova = create_model(x, y, n, num_obs,\n",
    "#                      num_subjects, num_position_levels, num_condition_levels)\n",
    "# batched_anova = create_model(x_batches, y_batches, n_batches, batch_size,\n",
    "#                              num_subjects, num_position_levels, num_condition_levels)\n",
    "\n",
    "p2e = per_board_pivot.position_type.astype('category').cat.codes.values\n",
    "c2e = per_board_pivot.condition_indicator.astype('category').cat.codes.values\n",
    "s2e = per_board_pivot.usubject.astype('category').cat.codes.values\n",
    "# model_2e = create_2e_model(p2e, c2e, s2e, num_obs, y, n, \n",
    "#                            num_subjects, num_position_levels, num_condition_levels)\n",
    "model_nodp = create_nodp_model(p2e, c2e, s2e, y, n, num_obs,\n",
    "                               num_subjects, num_position_levels, num_condition_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_nodp:\n",
    "    step = pm.NUTS(target_accept=.99)\n",
    "    trace = pm.sample(2000, step, tune=500, cores=8, init='advi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  varnames=['intercept', 'position_contrast', 'condition_contrast'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with batched_anova:\n",
    "    svgd = pm.SVGD(n_particles=200)\n",
    "    approximation = pm.fit(1000, method=svgd, obj_optimizer=pm.sgd(learning_rate=0.01),\n",
    "                           callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "    \n",
    "with anova:\n",
    "    step = pm.NUTS(target_accept=.99)\n",
    "    hierarchical_trace = pm.sample(2000, step, \n",
    "                                   tune=500, cores=8,\n",
    "                                   start=approximation.sample()[0], \n",
    "                                   progressbar=True)\n",
    "#     anova_trace = pm.sample(4000, tune=500, cores=4, init='advi', n_init=1000,\n",
    "#                             nuts_kwargs={'target_accept': .99})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximation.sample(1000)['position_contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(approximation.sample(10000)['intercept'].flatten(), label='SVGD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.StudentT('intercept', mu=0, nu=2, lam=.001, shape=[1])\n",
    "    a_position, b_position = get_noncentered_coeffs('position', [2])\n",
    "    a_condition, b_condition = get_noncentered_coeffs('condition', [2])\n",
    "    _, b_interaction = get_noncentered_coeffs('interaction', [4])\n",
    "    _, b_subject = get_noncentered_coeffs('subject', [len(subject_dummies.columns)])\n",
    "    \n",
    "    coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "#     coeffs = T.concatenate([b0, b_position, b_condition, b_interaction])\n",
    "    coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "    \n",
    "#     mu = T.nnet.sigmoid(T.dot(all_dummies.values, coeffs))\n",
    "    mu = T.nnet.sigmoid(T.dot(x_batches, coeffs))\n",
    "\n",
    "    kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "#     theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(per_board_pivot))\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=n_batches,\n",
    "                    p=theta,\n",
    "                    observed=y_batches)\n",
    "    \n",
    "    # Contrasts\n",
    "    position_contrast = pm.Deterministic('position_contrast', \n",
    "                                         a_position[1] - a_position[0])\n",
    "    condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                          a_condition[1] - a_condition[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    svgd = pm.SVGD()\n",
    "    approximation = pm.fit(10000, method=svgd, obj_optimizer=pm.sgd(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(approximation.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(approximation.sample(100000)['position_contrast'], label='SVGD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['intercept', 'position_contrast', 'condition_contrast'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    a0 = pm.Normal('intercept', mu=0, sd=10, shape=[1])\n",
    "    \n",
    "    sds_position = pm.HalfStudentT('a_position_std', nu=4, sigma=2.5, shape=[2])\n",
    "    a_position = pm.Normal('a_position', mu=0, sd=sds_position, shape=[2])\n",
    "    \n",
    "    sds_condition = pm.HalfStudentT('a_condition_std', nu=4, sigma=2.5, shape=[2])\n",
    "    a_condition = pm.Normal('a_condition', mu=0, sd=sds_condition, shape=[2])\n",
    "    \n",
    "    sds_interaction = pm.HalfStudentT('a_interaction_std', nu=4, sigma=2.5, shape=[4])\n",
    "    a_interaction = pm.Normal('a_interaction', mu=0, sd=sds_interaction, shape=[4])\n",
    "    \n",
    "    sds_subject = pm.HalfStudentT('a_subject_sds', nu=4, sigma=2.5, \n",
    "                                  shape=[len(subject_dummies.columns)])\n",
    "    a_subject = pm.Normal('a_subject', mu=0, sd=sds_subject, \n",
    "                          shape=[len(subject_dummies.columns)])\n",
    "    \n",
    "    b0 = a0 #+ a_position.mean() + a_condition.mean() + a_subject.mean() + a_interaction.mean()\n",
    "    b_position = a_position - a_position.mean()\n",
    "    b_condition = a_condition - a_condition.mean()\n",
    "    b_interaction = a_interaction - a_interaction.mean()\n",
    "    b_subject = a_subject - a_condition.mean()\n",
    "    \n",
    "    coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "    coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "    \n",
    "    mu = T.nnet.sigmoid(T.dot(all_dummies.values, coeffs))\n",
    "\n",
    "#     kappa = pm.HalfNormal('beta_variance', sigma=1)\n",
    "    kappa = pm.Gamma('beta_variance', mu=1, sigma=10)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(per_board_pivot))\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=per_board_pivot['occupied'].values,\n",
    "                    p=theta,\n",
    "                    observed=per_board_pivot['errors_2'].values)\n",
    "    \n",
    "    # Contrasts\n",
    "    position_contrast = pm.Deterministic('position_contrast', \n",
    "                                         a_position[1] - a_position[0])\n",
    "    condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                          a_condition[1] - a_condition[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['coeffs'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally (finally!) use count df and patsy formula \n",
    "# to generate regression indicator endogenous data\n",
    "# and count exogenous data\n",
    "\n",
    "formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "# formula = 'errors_2 ~ C(condition_indicator) + C(position_type)'\n",
    "endogenous_df, exogenous_df = pt.dmatrices(formula, per_board_pivot, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.Normal('intercept', mu=0, sd=1, shape=[1])\n",
    "    sds = pm.HalfStudentT('coeff_std', nu=4, sigma=2.5, shape=exogenous_df.shape[1]-1)\n",
    "    b = pm.Normal('coeffs', mu=0, sd=sds, shape=exogenous_df.shape[1]-1)\n",
    "\n",
    "    # Estimate mean of beta prior as sigmoid\n",
    "    mu = T.nnet.sigmoid(T.dot(exogenous_df.values, T.concatenate([b0, b])))\n",
    "\n",
    "#     kappa = pm.HalfNormal('beta_variance', sigma=1)\n",
    "    kappa = pm.Gamma('beta_variance', mu=1, sigma=10)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(exogenous_df))\n",
    "#     y = pm.Bernoulli('tagets', p=theta, observed=endogenous_df['errors_2'].values)\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=per_board_pivot['occupied'].values,\n",
    "                    p=theta,\n",
    "                    observed=endogenous_df['errors_2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['intercept', 'coeffs'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
