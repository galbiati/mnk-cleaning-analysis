{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# Numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy as pt\n",
    "import pymc3 as pm\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from theano import tensor as T\n",
    "\n",
    "# Internal libraries\n",
    "sys.path.append('../../src')\n",
    "\n",
    "# import lib.reconstruction.errors as errs\n",
    "from lib.reconstruction.errors import get_errors_per_location\n",
    "from lib.reconstruction.neighbors import FilterByOccupied\n",
    "from lib.reconstruction.neighbors import get_adjacency, get_adjacency_per_location\n",
    "\n",
    "from lib.reconstruction.bayes.poisson import build_poisson_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configuration\n",
    "pd.set_option('display.max_columns', 40)\n",
    "# os.environ['THEANO_FLAGS'] = 'device=cuda,floatX=float32'\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "\n",
    "colors = sns.cubehelix_palette(n_colors=2, start=0.5, hue=1, rot=.1, light=.65) \n",
    "colors += sns.cubehelix_palette(n_colors=2, start=2.5, hue=1, rot=.1, light=.65)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.read_csv('../../etc/reconstruction/tidy_data.csv', index_col=0)\n",
    "\n",
    "tidy['Condition'] = tidy['Condition'].map(lambda x: 'Untrained' if x == 'Naive' else x)\n",
    "tidy['Position ID'] = tidy['Position ID'].map(int)\n",
    "\n",
    "vals = ['Black Position', 'White Position', \n",
    "        'Is Real', 'Num Pieces']\n",
    "\n",
    "board_set = tidy.pivot_table(index='Position ID', \n",
    "                             values=vals, \n",
    "                             aggfunc=lambda x: x.unique()[0])[vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the adjacency of each location\n",
    "\n",
    "adjacencies = board_set.apply(get_adjacency_per_location, axis=1)\n",
    "\n",
    "adjacency_column_names = ['adjacency_all', \n",
    "                          'adjacency_same', \n",
    "                          'adjacency_opposite']\n",
    "\n",
    "adjacency_df = pd.DataFrame(adjacencies.tolist(), \n",
    "                            index=board_set.index, \n",
    "                            columns=adjacency_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupied_mask(row):\n",
    "    \"\"\"Return indicators for whether a piece was at a location\"\"\"\n",
    "    bp = np.stack([int(i) for i in row['Black Position']])\n",
    "    wp = np.stack([int(i) for i in row['White Position']])\n",
    "    p = bp + wp\n",
    "    return p.tolist()\n",
    "\n",
    "def get_condition_mask(condition):\n",
    "    \"\"\"Return convenience indicators for condition\"\"\"\n",
    "    return [condition, ] * 36\n",
    "\n",
    "for error_type in range(1, 4):\n",
    "    tidy[f'errors_{error_type}'] = tidy.apply(\n",
    "        lambda x: get_errors_per_location(x, str(error_type)), axis=1)\n",
    "\n",
    "# Compute occupancy and condition indicators \n",
    "# for each location on each trial\n",
    "tidy['occupied'] = tidy.apply(get_occupied_mask, axis=1)\n",
    "tidy['condition_mask'] = tidy['Condition'].map(get_condition_mask)\n",
    "\n",
    "# For convenience, \n",
    "# pull per-location adjacency statistics for each trial\n",
    "# into the per-trial dataframe\n",
    "tidy['adjacency_same'] = tidy['Position ID'].map(adjacency_df['adjacency_same'])\n",
    "tidy['adjacency_opposite'] = tidy['Position ID'].map(adjacency_df['adjacency_opposite'])\n",
    "\n",
    "# Convert the subject UID to an integer index\n",
    "subject_ids = tidy['Subject ID'].unique()\n",
    "subject_index = np.arange(len(subject_ids))\n",
    "subject_index_map = dict(zip(subject_ids, subject_index))\n",
    "\n",
    "tidy['subject_idx'] = tidy['Subject ID'].map(subject_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rates(df):\n",
    "    \"\"\"(DEPRECATED?) Return type 2 average error rates in a vector\"\"\"\n",
    "    return np.stack(df['errors_2'], axis=1).mean(axis=1)\n",
    "\n",
    "# Per-position mean error rates (over subjects)\n",
    "g = tidy.groupby('Position ID')\n",
    "board_set['errors'] = g.apply(get_error_rates)\n",
    "\n",
    "# Get a dummy array of location indices for convenience\n",
    "board_set['location_idx'] = np.tile(np.arange(36, dtype=np.uint8), [len(board_set), 1]).tolist()\n",
    "\n",
    "# Get distances to center as a dummy field\n",
    "# (same for all positions!)\n",
    "blank_board = np.zeros((4, 9))\n",
    "center = (blank_board.shape[0] / 2 - .5, blank_board.shape[1] / 2 - .5)\n",
    "\n",
    "distances = np.sqrt(((np.argwhere(blank_board == 0) - center) ** 2).sum(axis=1))\n",
    "board_set['distance_to_center'] = np.tile(distances, [len(board_set), 1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct filter functions\n",
    "occupied_error_filter = FilterByOccupied('errors')\n",
    "occupied_same_filter = FilterByOccupied('adjacency_same')\n",
    "occupied_opposite_filter = FilterByOccupied('adjacency_opposite')\n",
    "occupied_distances_filter = FilterByOccupied('distance_to_center')\n",
    "\n",
    "# Create a dataframe with both board set metadata and adjacency measures\n",
    "sum_df = pd.concat([board_set, adjacency_df], axis=1)\n",
    "\n",
    "# Apparently there were some null outputs here? \n",
    "# Don't recall why...\n",
    "sum_df = sum_df.loc[pd.notnull(sum_df['errors'])]\n",
    "\n",
    "# For each board, filter the measurements to discard unoccupied locations\n",
    "sum_df['occupied_errors'] = sum_df.apply(occupied_error_filter, axis=1)\n",
    "sum_df['occupied_adjacency_same'] = sum_df.apply(occupied_same_filter, axis=1)\n",
    "sum_df['occupied_adjacency_opposite'] = sum_df.apply(occupied_opposite_filter, axis=1)\n",
    "sum_df['occupied_distance_to_center'] = sum_df.apply(occupied_distances_filter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data for use with PyMC3\n",
    "# New dataframe should have *locations* in individual rows\n",
    "\n",
    "def expand_indicators(x):\n",
    "    return np.stack([int(x), ] * 36)\n",
    "\n",
    "# Extract exogenous variables\n",
    "x_same = np.concatenate(tidy['adjacency_same'].values)\n",
    "x_opposite = np.concatenate(tidy['adjacency_opposite'].values)\n",
    "x_occupied = np.concatenate(tidy['occupied'].values)\n",
    "x_condition_mask = np.concatenate(tidy['condition_mask'].values)\n",
    "\n",
    "x_subject = np.concatenate(tidy['subject_idx'].map(expand_indicators).values)\n",
    "x_position_type = np.concatenate(tidy['Is Real'].map(expand_indicators).values)\n",
    "x_position_id = np.concatenate(tidy['Position ID'].map(expand_indicators).values)\n",
    "\n",
    "# Extract endogenous variables\n",
    "y1 = np.concatenate(tidy['errors_1'].values)\n",
    "y2 = np.concatenate(tidy['errors_2'].values)\n",
    "y3 = np.concatenate(tidy['errors_3'].values)\n",
    "\n",
    "columns = ['subject', 'condition_mask', 'occupied', \n",
    "           'same', 'opposite', \n",
    "           'position_type', 'position_id',\n",
    "           'errors_1', 'errors_2', 'errors_3']\n",
    "                               \n",
    "df_data = np.stack((x_subject, x_condition_mask, x_occupied, \n",
    "                    x_same, x_opposite, \n",
    "                    x_position_type, x_position_id,\n",
    "                    y1, y2, y3)).T\n",
    "\n",
    "bayes_model_df = pd.DataFrame(data=df_data, columns=columns)\n",
    "\n",
    "# Force pandas to use integers\n",
    "# Why doesn't it by default? Who knows, but it's dumb.\n",
    "for c in bayes_model_df.columns:\n",
    "    if c not in ['condition_mask', 'same', 'opposite']:\n",
    "        bayes_model_df[c] = bayes_model_df[c].astype(int)\n",
    "\n",
    "bayes_model_df['condition_indicator'] = bayes_model_df['condition_mask'].map(\n",
    "    {'Trained': 1, 'Untrained': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up condition and position type indicators\n",
    "trained_sel = bayes_model_df['condition_mask'] == 'Trained'\n",
    "untrained_sel = bayes_model_df['condition_mask'] == 'Untrained'\n",
    "natural_sel  = bayes_model_df['position_type'] == 1\n",
    "synthetic_sel = bayes_model_df['position_type'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert subject indices for columnar format\n",
    "# Eg, indexes start from 0 for both trained/untrained groups\n",
    "\n",
    "bayes_model_df.loc[untrained_sel, 'subject'] = bayes_model_df.loc[untrained_sel, 'subject'] % 19\n",
    "\n",
    "# But still cache a unique indicator for each subject\n",
    "bayes_model_df['usubject'] = bayes_model_df['subject'] \n",
    "bayes_model_df['usubject'] += bayes_model_df['condition_indicator'] * 19\n",
    "\n",
    "# Same for real/fake positions\n",
    "natural_ids = bayes_model_df.loc[natural_sel, 'position_id'].astype(int)\n",
    "bayes_model_df.loc[natural_sel, 'position_id'] = natural_ids - natural_ids.min()\n",
    "\n",
    "# Get an integer indicator for the *type* of error that was made\n",
    "# Where a 0 indicates no error\n",
    "error_columns = ['errors_1', 'errors_2', 'errors_3']\n",
    "bayes_model_df['has_error'] = bayes_model_df[error_columns].astype(int).sum(axis=1)\n",
    "\n",
    "error_sel = bayes_model_df['has_error'] == 1\n",
    "\n",
    "error_values = bayes_model_df.loc[error_sel, error_columns].values\n",
    "error_types = np.argmax(error_values, axis=1) + 1\n",
    "\n",
    "bayes_model_df['error_type'] = 0\n",
    "bayes_model_df.loc[error_sel, 'error_type'] = error_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pivot table, per subject, for locations with errors\n",
    "has_error_df = bayes_model_df.loc[error_sel]\n",
    "bayes_subject_piv = has_error_df.pivot_table(index='usubject', \n",
    "                                             columns='error_type',\n",
    "                                             values='position_id',\n",
    "                                             aggfunc=len)\n",
    "\n",
    "# Total counts\n",
    "bayes_subject_piv['n'] = bayes_subject_piv[[1, 2, 3]].sum(axis=1)\n",
    "\n",
    "# Group indicator\n",
    "bayes_subject_piv['group'] = has_error_df.pivot_table(index='usubject',\n",
    "                                                      values='condition_indicator',\n",
    "                                                      aggfunc=lambda x: np.unique(x)[0])\n",
    "\n",
    "# Melt it back down to get a table of per-error-type count data\n",
    "# including group indicators and totals\n",
    "melted_df = pd.melt(bayes_subject_piv, \n",
    "                    id_vars=['group'], \n",
    "                    value_vars=[1, 2, 3], \n",
    "                    value_name='error_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayes_model_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_coeff(name, shape):\n",
    "#     sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#     noise = pm.Normal(f'noise_{name}', mu=0, sd=1, shape=shape)\n",
    "#     a = pm.Deterministic(f'a_{name}', noise * sigma)\n",
    "    \n",
    "#     return a\n",
    "\n",
    "\n",
    "# def create_model(position_index, condition_index, subject_index, y, batch_size,\n",
    "#                  num_subjects, num_position_levels, num_condition_levels): \n",
    "    \n",
    "#     num_interaction_levels = num_position_levels * num_condition_levels\n",
    "    \n",
    "#     with pm.Model() as model:\n",
    "#         b0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        \n",
    "#         a_position = create_coeff('position', num_position_levels)\n",
    "#         a_condition = create_coeff('condition', num_condition_levels)\n",
    "#         a_subject = create_coeff('subject', num_subjects)\n",
    "\n",
    "#         b_position = a_position - a_position.mean()\n",
    "#         b_condition = a_condition - a_condition.mean()\n",
    "#         b_subject = a_subject - a_subject.mean()\n",
    "        \n",
    "#         mu = b0\n",
    "#         mu += b_position[position_index]\n",
    "#         mu += b_condition[condition_index]\n",
    "#         mu += b_subject[subject_index]\n",
    "#         mu = pm.Deterministic('mu', T.nnet.sigmoid(mu))\n",
    "        \n",
    "#         kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "#         alpha = mu * kappa + 1\n",
    "#         beta = (1 - mu) * kappa + 1\n",
    "        \n",
    "#         theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "#         y = pm.Bernoulli('targets', p=theta, observed=y)\n",
    "        \n",
    "#         position_contrast = pm.Deterministic('position_contrast', \n",
    "#                                              a_position[1] - a_position[0])\n",
    "#         condition_contrast = pm.Deterministic('condition_contrast', \n",
    "#                                               a_condition[1] - a_condition[0])\n",
    "        \n",
    "#     return model\n",
    "\n",
    "# y = bayes_model_df['errors_2'].values\n",
    "# num_obs = len(y)\n",
    "\n",
    "# position_index = bayes_model_df.position_type.astype('category').cat.codes.values\n",
    "# condition_index = bayes_model_df.condition_indicator.astype('category').cat.codes.values\n",
    "# subject_index = bayes_model_df.usubject.astype('category').cat.codes.values\n",
    "\n",
    "# num_position_levels = len(bayes_model_df.position_type.unique())\n",
    "# num_condition_levels = len(bayes_model_df.condition_indicator.unique())\n",
    "# num_subjects = len(bayes_model_df.usubject.unique())\n",
    "\n",
    "# model = create_model(position_index, condition_index, subject_index, y, num_obs, \n",
    "#                      num_subjects, num_position_levels, num_condition_levels)\n",
    "\n",
    "# with model:\n",
    "#     step = pm.NUTS(target_accept=.98)\n",
    "#     trace = pm.sample(4000, step, tune=500, chains=8, cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_board_pivot = bayes_model_df.pivot_table(index=('usubject', 'position_id'),\n",
    "                                            values=('errors_2', 'occupied'),\n",
    "                                            aggfunc=np.sum)\n",
    "per_board_pivot['position_type'] = bayes_model_df.pivot_table(\n",
    "    index=('usubject', 'position_id'), values='position_type', \n",
    "    aggfunc=lambda x: x.unique()[0])\n",
    "\n",
    "per_board_pivot['condition_indicator'] = bayes_model_df.pivot_table(\n",
    "    index=('usubject', 'position_id'), values='condition_indicator', \n",
    "    aggfunc=lambda x: x.unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_board_pivot['usubject'] = per_board_pivot.index.get_level_values('usubject')\n",
    "per_board_pivot['position_id'] = per_board_pivot.index.get_level_values('position_id')\n",
    "\n",
    "per_board_pivot.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_board_pivot['interaction'] = per_board_pivot.apply(\n",
    "    lambda row: str(row['position_type']) + str(row['condition_indicator']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_idx_ = ('usubject', 'position_type', 'condition_indicator',)\n",
    "piv_vals_ = ('errors_2', 'occupied')\n",
    "high_piv = bayes_model_df.pivot_table(index=piv_idx_, values=piv_vals_, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_piv['usubject'] = high_piv.index.get_level_values('usubject')\n",
    "high_piv['position_type'] = high_piv.index.get_level_values('position_type')\n",
    "high_piv['condition_indicator'] = high_piv.index.get_level_values('condition_indicator')\n",
    "high_piv.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_piv['interaction'] = high_piv.apply(\n",
    "    lambda row: str(row['position_type']) + str(row['condition_indicator']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "high_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = per_board_pivot['occupied'].values\n",
    "# y = per_board_pivot['errors_2'].values\n",
    "\n",
    "n = high_piv['occupied'].values\n",
    "y = high_piv['errors_2'].values\n",
    "\n",
    "num_position_levels = len(bayes_model_df.position_type.unique())\n",
    "num_condition_levels = len(bayes_model_df.condition_indicator.unique())\n",
    "num_interaction_levels = num_position_levels * num_condition_levels\n",
    "num_subjects = len(bayes_model_df.usubject.unique())\n",
    "\n",
    "num_obs = len(y)\n",
    "batch_size = num_obs\n",
    "\n",
    "# x_batches = pm.Minibatch(x, batch_size=batch_size)\n",
    "# n_batches = pm.Minibatch(n, batch_size=batch_size)\n",
    "# y_batches = pm.Minibatch(y, batch_size=batch_size)\n",
    "\n",
    "# p2e = per_board_pivot.position_type.astype('category').cat.codes.values\n",
    "# c2e = per_board_pivot.condition_indicator.astype('category').cat.codes.values\n",
    "# i2e = per_board_pivot.interaction.astype('category').cat.codes.values\n",
    "# s2e = per_board_pivot.usubject.astype('category').cat.codes.values\n",
    "\n",
    "p2e = high_piv.position_type.astype('category').cat.codes.values\n",
    "c2e = high_piv.condition_indicator.astype('category').cat.codes.values\n",
    "i2e = high_piv.interaction.astype('category').cat.codes.values\n",
    "s2e = high_piv.usubject.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No condition split-plot BANOVA design\n",
    "# TODO:\n",
    "# This needs to only have coefficients for subject and position type\n",
    "# Then a deterministic var that computes \n",
    "# mean(subjects[trained]) - mean(subjects[untrained])\n",
    "\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=num_subjects)\n",
    "        y = pm.Binomial('targets', p=theta[subject_index], n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction, a_subject])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No subject split-plot BANOVA design\n",
    "# In standard BANOVA, when each subject belongs to only one condition,\n",
    "# condition and subject are in a sense confounded\n",
    "\n",
    "# That is, all variability due to condition \n",
    "# could be capture in the subject coefficients\n",
    "\n",
    "# This modification of ANOVA treats subjects as noise instead,\n",
    "# with a shared logistic prior \n",
    "# that only includes condition, position type, and interaction\n",
    "\n",
    "# I suppose one further alternative is to do some post processing on\n",
    "# sampled values: for each condition coefficient, \n",
    "# add the mean of all of that condition's subjects' coefficients\n",
    "# and subtract that mean from all that condition's subjects' coefficients\n",
    "\n",
    "# This will \"correct\" the estimated condition coefficients \n",
    "# to contain *all* the variance from subjects within that condition\n",
    "\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coeff(name, shape, sigma=None):\n",
    "    if sigma is None:\n",
    "#         sigma = pm.HalfStudentT(f'sigma_{name}', nu=2, lam=.1)\n",
    "          sigma = pm.Gamma(f'sigma', 1.64, .32)\n",
    "#     noise = pm.Normal(f'noise_{name}', mu=0, sd=1, shape=shape)\n",
    "#     a = pm.Deterministic(f'a_{name}', noise * sigma)\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        sigma = pm.Gamma(f'sigma', 1.64, .32)\n",
    "        \n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        a_subject = create_coeff('subject', num_subjects)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu += a_subject[subject_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "        kappa = pm.Gamma('beta_variance', .1, .1)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "#         a = T.concatenate([a_position, a_condition, a_interaction])\n",
    "#         m = pm.Deterministic('m', a0 + a)\n",
    "#         bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "#         bb = pm.Deterministic('bb', m - bb0)\n",
    "\n",
    "        # Reparameterize as deflections\n",
    "        # First, correct condition by subjects\n",
    "        \n",
    "        # Get the mean per group of subjects\n",
    "        a_sub_x_cond = a_subject.reshape((-1, 2))\n",
    "        m_sub_x_cond = T.mean(a_sub_x_cond, axis=0) # shape: (1, 2)\n",
    "        \n",
    "        # Add it to conditions and subtract it from subjects\n",
    "        b_condition_ = pm.Deterministic('b_condition_', a_condition + m_sub_x_cond)\n",
    "        b_subject_ = a_sub_x_cond - m_sub_x_cond\n",
    "        b_subject_ = pm.Deterministic('b_subject_', b_subject_.reshape((-1, )))\n",
    "    \n",
    "        m_position = T.mean(a_position)\n",
    "        m_condition = T.mean(b_condition_)\n",
    "        m_subject = T.mean(b_subject_)\n",
    "        m_interaction = T.mean(a_interaction)\n",
    "\n",
    "        b_position = pm.Deterministic('b_position', a_position - m_position)        \n",
    "        b_condition = pm.Deterministic('b_condition', b_condition_ - m_condition)\n",
    "        b_interaction = pm.Deterministic('b_interaction', a_interaction - m_interaction)\n",
    "        b_subject = pm.Deterministic('b_subject', b_subject_ - m_subject)\n",
    "        b0 = pm.Deterministic('b_intercept', \n",
    "                              a0 + m_position + m_condition + m_interaction + m_subject)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('contrast_position', \n",
    "                                             b_position[1] - b_position[0])\n",
    "        condition_contrast = pm.Deterministic('contrast_condition', \n",
    "                                              b_condition[1] - b_condition[0])\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Last edited 2019.09.14 8am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BANOVAModel(object):\n",
    "    def __init__(self, batch_size):\n",
    "        self.model = pm.Model()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def create_coefficient(self, name, shape, sigma=None):\n",
    "        if sigma is None:\n",
    "            sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "\n",
    "        a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "        return a\n",
    "    \n",
    "    def create_likelihood(self, omega, n, y):\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, \n",
    "                        shape=self.batch_size)\n",
    "        \n",
    "        targets = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def create_model(self, position_index, interaction_index, subject_index, n, y):\n",
    "        with self.model:\n",
    "            a_s = self.create_coefficient('subject', self.num_subjects)\n",
    "            a_p = self.create_coefficient('position', self.num_position_levels)\n",
    "            a_i = self.create_coefficient('interaction', self.num_interaction_levels)\n",
    "            \n",
    "            mu = a_position[position_index]\n",
    "            mu += a_interaction[interaction_index]\n",
    "            mu += a_subject[subject_index]\n",
    "            mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "            omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "            \n",
    "            targets = self.create_likelihood(omega, n, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coeff(name, shape, sigma=None):\n",
    "    if sigma is None:\n",
    "        sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "        \n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    return a\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    # Model without explicit condition or intercept\n",
    "    with pm.Model() as model: \n",
    "        # Coefficients with independent priors on variance\n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "#         a_subject = create_coeff('subject', num_subjects)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        \n",
    "        # Regression equation\n",
    "        mu = a_position[position_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "#         mu += a_subject[subject_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(mu))\n",
    "        \n",
    "        # Convert to beta parameters\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        # Sample probabilities and targets\n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        # Reparameterize as deflections\n",
    "        # First, correct condition by subjects\n",
    "        \n",
    "        # Get the mean per group of subjects\n",
    "#         a_sub_x_cond = a_subject.reshape((-1, 2))\n",
    "#         m_sub_x_cond = T.mean(a_sub_x_cond, axis=0) # shape: (1, 2)\n",
    "        \n",
    "        # Add it to conditions and subtract it from subjects\n",
    "#         b_condition_ = pm.Deterministic('b_condition_', a_condition + m_sub_x_cond)\n",
    "#         a_condition = pm.Deterministic('a_condition', m_sub_x_cond)\n",
    "#         a_subject_ = a_sub_x_cond - m_sub_x_cond\n",
    "#         a_subject_ = pm.Deterministic('a_subject_minus_condition', \n",
    "#                                       a_subject_.reshape((-1, )))\n",
    "    \n",
    "        m_position = T.mean(a_position)\n",
    "        m_condition = T.mean(a_condition)\n",
    "#         m_subject = T.mean(a_subject_)\n",
    "        m_interaction = T.mean(a_interaction)\n",
    "        \n",
    "        b_intercept = pm.Deterministic('b_intercept', \n",
    "                                       pm.logit(m_condition + m_position + m_interaction))\n",
    "        \n",
    "#         b_subject = pm.Deterministic('b_subject', a_subject_ - m_subject)\n",
    "        b_position = pm.Deterministic('b_position', pm.logit(a_position - m_position))   \n",
    "        b_condition = pm.Deterministic('b_condition', pm.logit(a_condition - m_condition))\n",
    "        b_interaction = pm.Deterministic('b_interaction', pm.logit(a_interaction - m_interaction))\n",
    "        \n",
    "        position_contrast = pm.Deterministic('contrast_position', \n",
    "                                             b_position[1] - b_position[0])\n",
    "        condition_contrast = pm.Deterministic('contrast_condition', \n",
    "                                              b_condition[1] - b_condition[0])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(p2e, c2e, i2e, s2e, y, n, batch_size,\n",
    "                     num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                     num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS(target_accept=.99, max_treedepth=15)\n",
    "    trace = pm.sample(4000, step, tune=6000, chains=8, cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "# pm.traceplot(trace, var_names=('b_intercept', 'b_position', 'b_condition', 'b_interaction'), )\n",
    "pm.traceplot(trace, \n",
    "             var_names=('sigma_condition', 'sigma_position')\n",
    "#              var_names=('sigma', )\n",
    "            )\n",
    "sns.despine()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  var_names=('b_intercept', 'b_condition', 'b_interaction',\n",
    "                             'contrast_position', 'contrast_condition'),\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard split-plot BANOVA design\n",
    "def create_coeff(name, shape):\n",
    "    sigma = pm.Gamma(f'sigma_{name}', 1.64, .32)\n",
    "#     sigma = pm.HalfSTudentT(f'sigma_{})\n",
    "#     sigma = pm.HalfStudentT(f'sigma_{name}', lam=.001, nu=1,) + .1\n",
    "#     noise = pm.Normal(f'noise_{name}', mu=0, sd=1, shape=shape)\n",
    "#     a = pm.Deterministic(f'a_{name}', noise * (sigma + .01))\n",
    "    a = pm.Normal(f'a_{name}', mu=0, tau=1/sigma**2, shape=shape)\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "def create_model(position_index, condition_index, interaction_index, subject_index, \n",
    "                 y, n, batch_size,\n",
    "                 num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                 num_subjects): \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        a0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        \n",
    "        a_position = create_coeff('position', num_position_levels)\n",
    "        a_condition = create_coeff('condition', num_condition_levels)\n",
    "        a_interaction = create_coeff('interaction', num_interaction_levels)\n",
    "        a_subject = create_coeff('subject', num_subjects)\n",
    "        \n",
    "        mu = a0\n",
    "        mu += a_position[position_index]\n",
    "        mu += a_condition[condition_index]\n",
    "        mu += a_interaction[interaction_index]\n",
    "        mu += a_subject[subject_index]\n",
    "        mu = pm.Deterministic('mu', mu)\n",
    "\n",
    "        omega = pm.Deterministic('omega', T.nnet.sigmoid((mu)))\n",
    "        \n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = omega * (kappa - 2) + 1\n",
    "        beta = (1 - omega) * (kappa - 2) + 1\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', p=theta, n=n, observed=y)\n",
    "\n",
    "        a = T.concatenate([a_position, a_condition, a_interaction, a_subject])\n",
    "        m = pm.Deterministic('m', a0 + a)\n",
    "        bb0 = pm.Deterministic('bb0', T.mean(m))\n",
    "        bb = pm.Deterministic('bb', m - bb0)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('bb_pos', bb[1] - bb[0])\n",
    "        condition_contrast = pm.Deterministic('bb_con', bb[3] - bb[2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(p2e, c2e, i2e, s2e, y, n, batch_size,\n",
    "                     num_position_levels, num_condition_levels, num_interaction_levels, \n",
    "                     num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS(target_accept=.99, max_treedepth=15)\n",
    "    trace = pm.sample(8000, step, tune=8000, chains=8, cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  varnames=['bb_pos', 'bb_con'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_dummies = pd.DataFrame(index=per_board_pivot.index, \n",
    "                                 data=np.ones(len(per_board_pivot)))\n",
    "position_dummies = pd.get_dummies(per_board_pivot.position_type)\n",
    "condition_dummies = pd.get_dummies(per_board_pivot.condition_indicator)\n",
    "interaction_dummies = pd.get_dummies(per_board_pivot.interaction)\n",
    "\n",
    "subject_dummies = pd.get_dummies(per_board_pivot.usubject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies = pd.concat([\n",
    "    intercept_dummies, \n",
    "    position_dummies, \n",
    "    condition_dummies, \n",
    "    interaction_dummies,\n",
    "    subject_dummies\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noncentered_coeffs(name, shape):\n",
    "    sd = pm.HalfStudentT(f'{name}_sd', nu=4, sigma=2.5, shape=shape)\n",
    "#     noise = pm.Normal(f'{name}_noise', mu=0, sd=1)\n",
    "#     a = pm.Deterministic(f'{name}_a', noise * sd)\n",
    "    a = pm.Normal(f'{name}_a', mu=0, sd=sd, shape=shape)\n",
    "    b = a - a.mean()\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def create_model(x, y, n, batch_size,\n",
    "                 num_subjects,\n",
    "                 num_position_levels, \n",
    "                 num_condition_levels): \n",
    "    \n",
    "    num_interaction_levels = num_position_levels * num_condition_levels\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # Create intercept coefficient; no prior on variance\n",
    "        b0 = pm.StudentT('intercept', mu=0, nu=2, lam=.001, shape=[1])\n",
    "        a_position, b_position = get_noncentered_coeffs('position', [num_position_levels])\n",
    "        a_condition, b_condition = get_noncentered_coeffs('condition', [num_condition_levels])\n",
    "        _, b_interaction = get_noncentered_coeffs('interaction', [num_interaction_levels])\n",
    "        _, b_subject = get_noncentered_coeffs('subject', [num_subjects])\n",
    "\n",
    "        coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "        coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "\n",
    "        mu = T.nnet.sigmoid(T.dot(x, coeffs))\n",
    "\n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = mu * kappa\n",
    "        beta = (1 - mu) * kappa\n",
    "\n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', n=n, p=theta, observed=y)\n",
    "\n",
    "        # Contrasts\n",
    "        position_contrast = pm.Deterministic('position_contrast', \n",
    "                                             a_position[1] - a_position[0])\n",
    "        condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                              a_condition[1] - a_condition[0])\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_2e_model(position_index, condition_index, subject_index, num_obs,\n",
    "                    y, n,\n",
    "                    num_subjects, num_position_levels, num_condition_levels):\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # Hyper parameters\n",
    "        a_sigma = pm.Gamma('aSigma', 1.64, 0.32, shape=2)\n",
    "        \n",
    "        # Intercept\n",
    "        a0 = pm.Normal('a0', 0.0, tau=1/2**2)\n",
    "        \n",
    "        # Parameters\n",
    "        a_position = pm.Normal('a_position', 0.0, tau=1/a_sigma[0]**2, \n",
    "                               shape=[1, num_position_levels]) \n",
    "        a_condition = pm.Normal('a_condition', 0.0,  tau=1/a_sigma[1]**2,\n",
    "                                shape=[num_condition_levels, 1])\n",
    "        \n",
    "        # Parameters for categories (Primary field positions)\n",
    "        omega = pm.Deterministic('omega', pm.invlogit(a0 + a_position + a_condition))\n",
    "        kappa = pm.Gamma('kappa', 0.01, 0.01)\n",
    "\n",
    "        # Parameter for individual players\n",
    "        theta_a = omega[position_index, condition_index] * kappa + 1\n",
    "        theta_b = (1 - omega[position_index, condition_index]) * kappa + 1\n",
    "        theta = pm.Beta('theta', theta_a, theta_b, shape=[num_subjects, num_obs])\n",
    "\n",
    "        y = pm.Binomial('y', n=n, p=theta[:, subject_index], observed=y)\n",
    "\n",
    "        # Convert a0,a to sum-to-zero b0,b \n",
    "        m = pm.Deterministic('m', a0 + a_position + a_condition)\n",
    "        b0 = pm.Deterministic('b0', T.mean(m))\n",
    "        b = pm.Deterministic('b', m - b0) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodp_model(position_index, condition_index, subject_index, \n",
    "                      y, n, batch_size,\n",
    "                      num_subjects, num_position_levels, num_condition_levels): \n",
    "    \n",
    "    num_interaction_levels = num_position_levels * num_condition_levels\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        b0 = pm.Normal('intercept', 0, tau=1/2**2)\n",
    "        \n",
    "        sigma_position = pm.Gamma('sigma_position', 1.64, 0.32)\n",
    "        noise_position = pm.Normal('noise_position', mu=0, sd=1, \n",
    "                                   shape=num_position_levels)\n",
    "        a_position = pm.Deterministic('a_position', \n",
    "                                      noise_position * 1/sigma_position**2)\n",
    "#         a_position = pm.Normal('a_position', mu=0, tau=1/sigma_position**2, \n",
    "#                                shape=num_position_levels)\n",
    "        \n",
    "        sigma_condition = pm.Gamma('sigma_condition', 1.64, 0.32)\n",
    "        noise_condition = pm.Normal('noise_condition', mu=0, sd=1,\n",
    "                                    shape=num_condition_levels)\n",
    "        a_condition = pm.Deterministic('a_condition',\n",
    "                                       noise_condition * 1/sigma_position**2)\n",
    "#         a_condition = pm.Normal('a_condition', mu=0, tau=1/sigma_condition**2, \n",
    "#                                 shape=num_condition_levels)\n",
    "        \n",
    "        sigma_subject = pm.Gamma('sigma_subject', 1.64, 0.32)\n",
    "        noise_subject = pm.Normal('noise_subject', mu=0, sd=1,\n",
    "                                  shape=num_subjects)\n",
    "        a_subject = pm.Deterministic('a_subject',\n",
    "                                     noise_subject * 1/sigma_subject**2)\n",
    "        \n",
    "#         a_subject = pm.Normal('a_subject', mu=0, tau=1/sigma_subject**2,\n",
    "#                               shape=num_subjects)\n",
    "\n",
    "        b_position = a_position - a_position.mean()\n",
    "        b_condition = a_condition - a_condition.mean()\n",
    "        b_subject = a_subject - a_subject.mean()\n",
    "        \n",
    "        mu = b0\n",
    "        mu += b_position[position_index]\n",
    "        mu += b_condition[condition_index]\n",
    "        mu += b_subject[subject_index]\n",
    "        \n",
    "#         mu = T.nnet.sigmoid(mu)\n",
    "#         mu = pm.Deterministic('mu', T.nnet.sigmoid(mu))\n",
    "        mu = pm.Deterministic('mu', pm.invlogit(mu))\n",
    "        \n",
    "        kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "        alpha = mu * kappa\n",
    "        beta = (1 - mu) * kappa\n",
    "        \n",
    "        theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "        y = pm.Binomial('targets', n=n, p=theta, observed=y)\n",
    "        \n",
    "        position_contrast = pm.Deterministic('position_contrast', \n",
    "                                             a_position[1] - a_position[0])\n",
    "        condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                              a_condition[1] - a_condition[0])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_dummies.values\n",
    "n = per_board_pivot['occupied'].values\n",
    "y = per_board_pivot['errors_2'].values\n",
    "\n",
    "num_obs = x.shape[0]\n",
    "\n",
    "# batch_size = 128\n",
    "batch_size = num_obs\n",
    "\n",
    "x_batches = pm.Minibatch(x, batch_size=batch_size)\n",
    "n_batches = pm.Minibatch(n, batch_size=batch_size)\n",
    "y_batches = pm.Minibatch(y, batch_size=batch_size)\n",
    "\n",
    "num_subjects = len(subject_dummies.columns)\n",
    "num_position_levels = 2\n",
    "num_condition_levels = 2\n",
    "\n",
    "# anova = create_model(x, y, n, num_obs,\n",
    "#                      num_subjects, num_position_levels, num_condition_levels)\n",
    "# batched_anova = create_model(x_batches, y_batches, n_batches, batch_size,\n",
    "#                              num_subjects, num_position_levels, num_condition_levels)\n",
    "\n",
    "p2e = per_board_pivot.position_type.astype('category').cat.codes.values\n",
    "c2e = per_board_pivot.condition_indicator.astype('category').cat.codes.values\n",
    "s2e = per_board_pivot.usubject.astype('category').cat.codes.values\n",
    "# model_2e = create_2e_model(p2e, c2e, s2e, num_obs, y, n, \n",
    "#                            num_subjects, num_position_levels, num_condition_levels)\n",
    "model_nodp = create_nodp_model(p2e, c2e, s2e, y, n, num_obs,\n",
    "                               num_subjects, num_position_levels, num_condition_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_nodp:\n",
    "    step = pm.NUTS(target_accept=.99)\n",
    "    trace = pm.sample(2000, step, tune=500, cores=8, init='advi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(trace, \n",
    "                  varnames=['intercept', 'position_contrast', 'condition_contrast'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with batched_anova:\n",
    "    svgd = pm.SVGD(n_particles=200)\n",
    "    approximation = pm.fit(1000, method=svgd, obj_optimizer=pm.sgd(learning_rate=0.01),\n",
    "                           callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "    \n",
    "with anova:\n",
    "    step = pm.NUTS(target_accept=.99)\n",
    "    hierarchical_trace = pm.sample(2000, step, \n",
    "                                   tune=500, cores=8,\n",
    "                                   start=approximation.sample()[0], \n",
    "                                   progressbar=True)\n",
    "#     anova_trace = pm.sample(4000, tune=500, cores=4, init='advi', n_init=1000,\n",
    "#                             nuts_kwargs={'target_accept': .99})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximation.sample(1000)['position_contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(approximation.sample(10000)['intercept'].flatten(), label='SVGD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.StudentT('intercept', mu=0, nu=2, lam=.001, shape=[1])\n",
    "    a_position, b_position = get_noncentered_coeffs('position', [2])\n",
    "    a_condition, b_condition = get_noncentered_coeffs('condition', [2])\n",
    "    _, b_interaction = get_noncentered_coeffs('interaction', [4])\n",
    "    _, b_subject = get_noncentered_coeffs('subject', [len(subject_dummies.columns)])\n",
    "    \n",
    "    coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "#     coeffs = T.concatenate([b0, b_position, b_condition, b_interaction])\n",
    "    coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "    \n",
    "#     mu = T.nnet.sigmoid(T.dot(all_dummies.values, coeffs))\n",
    "    mu = T.nnet.sigmoid(T.dot(x_batches, coeffs))\n",
    "\n",
    "    kappa = pm.Gamma('beta_variance', .01, .01)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "#     theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(per_board_pivot))\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=batch_size)\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=n_batches,\n",
    "                    p=theta,\n",
    "                    observed=y_batches)\n",
    "    \n",
    "    # Contrasts\n",
    "    position_contrast = pm.Deterministic('position_contrast', \n",
    "                                         a_position[1] - a_position[0])\n",
    "    condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                          a_condition[1] - a_condition[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    svgd = pm.SVGD()\n",
    "    approximation = pm.fit(10000, method=svgd, obj_optimizer=pm.sgd(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(approximation.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(approximation.sample(100000)['position_contrast'], label='SVGD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['intercept', 'position_contrast', 'condition_contrast'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    a0 = pm.Normal('intercept', mu=0, sd=10, shape=[1])\n",
    "    \n",
    "    sds_position = pm.HalfStudentT('a_position_std', nu=4, sigma=2.5, shape=[2])\n",
    "    a_position = pm.Normal('a_position', mu=0, sd=sds_position, shape=[2])\n",
    "    \n",
    "    sds_condition = pm.HalfStudentT('a_condition_std', nu=4, sigma=2.5, shape=[2])\n",
    "    a_condition = pm.Normal('a_condition', mu=0, sd=sds_condition, shape=[2])\n",
    "    \n",
    "    sds_interaction = pm.HalfStudentT('a_interaction_std', nu=4, sigma=2.5, shape=[4])\n",
    "    a_interaction = pm.Normal('a_interaction', mu=0, sd=sds_interaction, shape=[4])\n",
    "    \n",
    "    sds_subject = pm.HalfStudentT('a_subject_sds', nu=4, sigma=2.5, \n",
    "                                  shape=[len(subject_dummies.columns)])\n",
    "    a_subject = pm.Normal('a_subject', mu=0, sd=sds_subject, \n",
    "                          shape=[len(subject_dummies.columns)])\n",
    "    \n",
    "    b0 = a0 #+ a_position.mean() + a_condition.mean() + a_subject.mean() + a_interaction.mean()\n",
    "    b_position = a_position - a_position.mean()\n",
    "    b_condition = a_condition - a_condition.mean()\n",
    "    b_interaction = a_interaction - a_interaction.mean()\n",
    "    b_subject = a_subject - a_condition.mean()\n",
    "    \n",
    "    coeffs = T.concatenate([b0, b_position, b_condition, b_interaction, b_subject])\n",
    "    coeffs = pm.Deterministic('coeffs', coeffs)\n",
    "    \n",
    "    mu = T.nnet.sigmoid(T.dot(all_dummies.values, coeffs))\n",
    "\n",
    "#     kappa = pm.HalfNormal('beta_variance', sigma=1)\n",
    "    kappa = pm.Gamma('beta_variance', mu=1, sigma=10)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(per_board_pivot))\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=per_board_pivot['occupied'].values,\n",
    "                    p=theta,\n",
    "                    observed=per_board_pivot['errors_2'].values)\n",
    "    \n",
    "    # Contrasts\n",
    "    position_contrast = pm.Deterministic('position_contrast', \n",
    "                                         a_position[1] - a_position[0])\n",
    "    condition_contrast = pm.Deterministic('condition_contrast', \n",
    "                                          a_condition[1] - a_condition[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['coeffs'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  kind='hist',\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally (finally!) use count df and patsy formula \n",
    "# to generate regression indicator endogenous data\n",
    "# and count exogenous data\n",
    "\n",
    "formula = 'errors_2 ~ C(usubject, Sum) + C(condition_indicator, Sum) * C(position_type, Sum)'\n",
    "# formula = 'errors_2 ~ C(condition_indicator) + C(position_type)'\n",
    "endogenous_df, exogenous_df = pt.dmatrices(formula, per_board_pivot, \n",
    "                                           return_type='dataframe', \n",
    "                                           NA_action='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_anova:\n",
    "    # Create placeholder lists for PyMC RVs\n",
    "    sds = []\n",
    "    coeffs = []\n",
    "\n",
    "    # Create intercept coefficient; no prior on variance\n",
    "    b0 = pm.Normal('intercept', mu=0, sd=1, shape=[1])\n",
    "    sds = pm.HalfStudentT('coeff_std', nu=4, sigma=2.5, shape=exogenous_df.shape[1]-1)\n",
    "    b = pm.Normal('coeffs', mu=0, sd=sds, shape=exogenous_df.shape[1]-1)\n",
    "\n",
    "    # Estimate mean of beta prior as sigmoid\n",
    "    mu = T.nnet.sigmoid(T.dot(exogenous_df.values, T.concatenate([b0, b])))\n",
    "\n",
    "#     kappa = pm.HalfNormal('beta_variance', sigma=1)\n",
    "    kappa = pm.Gamma('beta_variance', mu=1, sigma=10)\n",
    "    alpha = mu * kappa\n",
    "    beta = (1 - mu) * kappa\n",
    "\n",
    "    theta = pm.Beta('theta', alpha=alpha, beta=beta, shape=len(exogenous_df))\n",
    "#     y = pm.Bernoulli('tagets', p=theta, observed=endogenous_df['errors_2'].values)\n",
    "    y = pm.Binomial('targets', \n",
    "                    n=per_board_pivot['occupied'].values,\n",
    "                    p=theta,\n",
    "                    observed=endogenous_df['errors_2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_anova:\n",
    "    anova_trace = pm.sample(8000, tune=1000, cores=4,\n",
    "                            nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "pm.plot_posterior(anova_trace, \n",
    "                  varnames=['intercept', 'coeffs'],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  ref_val=0);\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exogenous_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(range(len(exogenous_df.columns) - 1), exogenous_df.columns.values[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and display poisson model\n",
    "poisson_model = build_poisson_model(exogenous_df, endogenous_df['error_count'].values)\n",
    "pm.model_to_graphviz(poisson_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with poisson_model:\n",
    "    poisson_trace = pm.sample(16000, tune=4000, cores=4, \n",
    "                              nuts_kwargs={'target_accept': .99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(poisson_trace)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(poisson_trace, \n",
    "                  varnames=[f'b_error_type[T.{i}]_group' for i in range(1, 4)],\n",
    "                  color='#87ceeb',\n",
    "                  rope=(-.01, .01),\n",
    "                  ref_val=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(poisson_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = poisson_trace.get_values('b_error_type[T.2]_group')\n",
    "sd = np.std(samples)\n",
    "\n",
    "np.where((sd > samples) & (samples > -sd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
