{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "# Internal libraries\n",
    "sys.path.append('../../src')\n",
    "\n",
    "# import lib.reconstruction.errors as errs\n",
    "from lib.reconstruction.errors import get_errors_per_location\n",
    "from lib.reconstruction.neighbors import get_adjacency, get_adjacency_per_location\n",
    "\n",
    "from lib.reconstruction.bayes.data import BayesDFCompute\n",
    "from lib.reconstruction.bayes.binomial import build_binomial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configuration\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "colors = sns.cubehelix_palette(n_colors=2, start=0.5, hue=1, rot=.1, light=.65) \n",
    "colors += sns.cubehelix_palette(n_colors=2, start=2.5, hue=1, rot=.1, light=.65)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.read_csv('../../etc/reconstruction/tidy_data.csv', index_col=0)\n",
    "\n",
    "tidy['Condition'] = tidy['Condition'].map(lambda x: 'Untrained' if x == 'Naive' else x)\n",
    "tidy['Position ID'] = tidy['Position ID'].map(int)\n",
    "\n",
    "vals = ['Black Position', 'White Position', \n",
    "        'Is Real', 'Num Pieces']\n",
    "\n",
    "board_set = tidy.pivot_table(index='Position ID', \n",
    "                             values=vals, \n",
    "                             aggfunc=lambda x: x.unique()[0])[vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the adjacency of each location\n",
    "\n",
    "adjacencies = board_set.apply(get_adjacency_per_location, axis=1)\n",
    "\n",
    "adjacency_column_names = ['adjacency_all', \n",
    "                          'adjacency_same', \n",
    "                          'adjacency_opposite']\n",
    "\n",
    "adjacency_df = pd.DataFrame(adjacencies.tolist(), \n",
    "                            index=board_set.index, \n",
    "                            columns=adjacency_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupied_mask(row):\n",
    "    bp = np.stack([int(i) for i in row['Black Position']])\n",
    "    wp = np.stack([int(i) for i in row['White Position']])\n",
    "    p = bp + wp\n",
    "    return p.tolist()\n",
    "\n",
    "def get_condition_mask(condition):\n",
    "    return [condition, ] * 36\n",
    "\n",
    "tidy['occupied'] = tidy.apply(get_occupied_mask, axis=1)\n",
    "tidy['condition_mask'] = tidy['Condition'].map(get_condition_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy['adjacency_same'] = tidy['Position ID'].map(adjacency_df['adjacency_same'])\n",
    "tidy['adjacency_opposite'] = tidy['Position ID'].map(adjacency_df['adjacency_opposite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary data structures\n",
    "\n",
    "# Get a dummy array of location indices for convenience\n",
    "board_set['location_idx'] = np.tile(np.arange(36, dtype=np.uint8), [len(board_set), 1]).tolist()\n",
    "\n",
    "# Get distances to center as a dummy field\n",
    "blank_board = np.zeros((4, 9))\n",
    "center = (blank_board.shape[0] / 2 - .5, blank_board.shape[1] / 2 - .5)\n",
    "\n",
    "distances = np.sqrt(((np.argwhere(blank_board == 0) - center) ** 2).sum(axis=1))\n",
    "board_set['distance_to_center'] = np.tile(distances, [len(board_set), 1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = np.arange(len(tidy['Subject ID'].unique()))\n",
    "subject_idx_map = dict(zip(tidy['Subject ID'].unique(), unique_ids))\n",
    "\n",
    "tidy['subject_idx'] = tidy['Subject ID'].map(subject_idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_df = BayesDFCompute()\n",
    "\n",
    "model_df = get_model_df(tidy, board_set)\n",
    "# Filter for occupied positions only\n",
    "# model_df = model_df.loc[model_df['occupied'] == '1']\n",
    "model_df = model_df.loc[model_df['occupied'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sel = model_df['condition_mask'] == 'Trained'\n",
    "untrained_sel = model_df['condition_mask'] == 'Untrained'\n",
    "natural_sel  = model_df['position_type'] == '1'\n",
    "synthetic_sel = model_df['position_type'] == '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between stimulus types, per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose error type\n",
    "error_type = 'errors_1'\n",
    "\n",
    "nt_sel = natural_sel & trained_sel\n",
    "st_sel = synthetic_sel & trained_sel\n",
    "\n",
    "nu_sel = natural_sel & untrained_sel\n",
    "su_sel = synthetic_sel & untrained_sel\n",
    "\n",
    "data_dict_schema = {'trained': {'natural': nt_sel, 'synthetic': st_sel},\n",
    "                    'untrained': {'natural': nu_sel, 'synthetic_selhetic': su_sel},\n",
    "                    'natural': {'trained': nt_sel, 'untrained': nu_sel},\n",
    "                    'synthetic': {'trained': st_sel, 'untrained': su_sel}}\n",
    "\n",
    "# More like dictionary non-comprehension, amirite?\n",
    "data_dict = {\n",
    "    k_static: {\n",
    "        k_compare: {'x': model_df.loc[v_compare, 'position_id'].values.astype(int),\n",
    "                    'y': model_df.loc[v_compare, error_type].values.astype(int)}\n",
    "        for k_compare, v_compare in v_static.items()}\n",
    "    for k_static, v_static in data_dict_schema.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(data_dict_item):\n",
    "    model = build_binomial_model(data_dict_item)\n",
    "    \n",
    "    nuts_kwargs = {'target_accept': .98}\n",
    "    \n",
    "    with model:\n",
    "        race = pm.sample(16000, \n",
    "                         cores=4, tune=4000, \n",
    "                         nuts_kwargs=nuts_kwargs)\n",
    "        \n",
    "    sample = trace.get_values('difference in means')\n",
    "\n",
    "    print('p ROPE', len(np.where((-.01 < sample) & (sample < .01))[0]) / len(sample))\n",
    "    print('p < ROPE', len(sample[sample < -.01]) / len(sample))\n",
    "    print('p > ROPE', len(sample[sample > .01]) / len(sample))\n",
    "        \n",
    "    ax = pm.plot_posterior(trace, var_names=['difference in means'],\n",
    "                           ref_val=0, credible_interval=.95,\n",
    "                           kind='hist', figsize=(4, 3))\n",
    "    \n",
    "    return model, trace, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, trained_trace, trained_ax = run_inference(data_dict['trained'])\n",
    "\n",
    "plt.setp(trained_ax, \n",
    "         title='Natural - Synthetic; Trained subjects', \n",
    "         xlabel=r'$\\Delta$ Type I error rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = build_binomial_model(data_dict['untrained'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with untrained_model:\n",
    "    untrained_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "ax = pm.plot_posterior(untrained_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', \n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Natural - Synthetic; Untrained subjects', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between conditions, per stimulus type\n",
    "\n",
    "####  Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_model = build_binomial_model(data_dict['natural'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with natural_model:\n",
    "    natural_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pm.plot_posterior(natural_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', \n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Trained - Untrained; Natural positions', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = natural_trace.get_values('difference in means')\n",
    "\n",
    "print('p ROPE', len(np.where((-.01 < sample) & (sample < .01))[0]) / len(sample))\n",
    "print('p < ROPE', len(sample[sample < -.01]) / len(sample))\n",
    "print('p > ROPE', len(sample[sample > .01]) / len(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_model = build_binomial_model(data_dict['synthetic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with synthetic_model:\n",
    "    synthetic_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "ax = pm.plot_posterior(synthetic_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', round_to=3,\n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Trained - Untrained; Synthetic positions', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = synthetic_trace.get_values('difference in means')\n",
    "\n",
    "print('p ROPE', len(np.where((-.01 < sample) & (sample < .01))[0]) / len(sample))\n",
    "print('p < ROPE', len(sample[sample < -.01]) / len(sample))\n",
    "print('p > ROPE', len(sample[sample > .01]) / len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
