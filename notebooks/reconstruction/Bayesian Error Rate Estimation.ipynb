{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "# Internal libraries\n",
    "sys.path.append('../../src')\n",
    "\n",
    "# import lib.reconstruction.errors as errs\n",
    "from lib.reconstruction.errors import get_errors_per_location\n",
    "from lib.reconstruction.neighbors import get_adjacency, get_adjacency_per_location\n",
    "\n",
    "from lib.reconstruction.bayes.data import BayesDFCompute\n",
    "from lib.reconstruction.bayes.binomial import build_binomial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook configuration\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "colors = sns.cubehelix_palette(n_colors=2, start=0.5, hue=1, rot=.1, light=.65) \n",
    "colors += sns.cubehelix_palette(n_colors=2, start=2.5, hue=1, rot=.1, light=.65)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.read_csv('../../etc/reconstruction/tidy_data.csv', index_col=0)\n",
    "\n",
    "tidy['Condition'] = tidy['Condition'].map(lambda x: 'Untrained' if x == 'Naive' else x)\n",
    "tidy['Position ID'] = tidy['Position ID'].map(int)\n",
    "\n",
    "vals = ['Black Position', 'White Position', \n",
    "        'Is Real', 'Num Pieces']\n",
    "\n",
    "board_set = tidy.pivot_table(index='Position ID', \n",
    "                             values=vals, \n",
    "                             aggfunc=lambda x: x.unique()[0])[vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the adjacency of each location\n",
    "\n",
    "adjacencies = board_set.apply(get_adjacency_per_location, axis=1)\n",
    "\n",
    "adjacency_column_names = ['adjacency_all', \n",
    "                          'adjacency_same', \n",
    "                          'adjacency_opposite']\n",
    "\n",
    "adjacency_df = pd.DataFrame(adjacencies.tolist(), \n",
    "                            index=board_set.index, \n",
    "                            columns=adjacency_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupied_mask(row):\n",
    "    bp = np.stack([int(i) for i in row['Black Position']])\n",
    "    wp = np.stack([int(i) for i in row['White Position']])\n",
    "    p = bp + wp\n",
    "    return p.tolist()\n",
    "\n",
    "def get_condition_mask(condition):\n",
    "    return [condition, ] * 36\n",
    "\n",
    "tidy['occupied'] = tidy.apply(get_occupied_mask, axis=1)\n",
    "tidy['condition_mask'] = tidy['Condition'].map(get_condition_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy['adjacency_same'] = tidy['Position ID'].map(adjacency_df['adjacency_same'])\n",
    "tidy['adjacency_opposite'] = tidy['Position ID'].map(adjacency_df['adjacency_opposite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary data structures\n",
    "\n",
    "# Get a dummy array of location indices for convenience\n",
    "board_set['location_idx'] = np.tile(np.arange(36, dtype=np.uint8), [len(board_set), 1]).tolist()\n",
    "\n",
    "# Get distances to center as a dummy field\n",
    "blank_board = np.zeros((4, 9))\n",
    "center = (blank_board.shape[0] / 2 - .5, blank_board.shape[1] / 2 - .5)\n",
    "\n",
    "distances = np.sqrt(((np.argwhere(blank_board == 0) - center) ** 2).sum(axis=1))\n",
    "board_set['distance_to_center'] = np.tile(distances, [len(board_set), 1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = np.arange(len(tidy['Subject ID'].unique()))\n",
    "subject_idx_map = dict(zip(tidy['Subject ID'].unique(),\n",
    "                           unique_ids))\n",
    "\n",
    "tidy['subject_idx'] = tidy['Subject ID'].map(subject_idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_df = BayesDFCompute()\n",
    "\n",
    "model_df = get_model_df(tidy, board_set)\n",
    "# Filter for occupied positions only\n",
    "model_df = model_df.loc[model_df['occupied'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sel = model_df['condition_mask'] == 'Trained'\n",
    "untrained_sel = model_df['condition_mask'] == 'Untrained'\n",
    "natural_sel  = model_df['position_type'] == '1'\n",
    "synthetic_sel = model_df['position_type'] == '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between stimulus types, per condition\n",
    "\n",
    "#### Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: figure out how to generate one big dict (full of bad datas?)\n",
    "pos_natural = model_df.loc[natural_sel & trained_sel, 'position_id'].values.astype(int)\n",
    "err_natural = model_df.loc[natural_sel & trained_sel, 'errors_1'].values.astype(int)\n",
    "\n",
    "pos_synthetic = model_df.loc[synthetic_sel & trained_sel, 'position_id'].values.astype(int)\n",
    "err_synthetic = model_df.loc[synthetic_sel & trained_sel, 'errors_1'].values.astype(int)\n",
    "\n",
    "data_dict = {'natural': {'x': pos_natural, 'y': err_natural},\n",
    "             'synthetic': {'x': pos_synthetic, 'y': err_synthetic}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = build_binomial_model(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [p_synthetic, p_natural, kappa_synthetic, mu_synthetic, kappa_natural, mu_natural, rate, shape, kappa, mu]\n",
      "Sampling 4 chains:  34%|███▍      | 27265/80000 [24:26<1:41:08,  8.69draws/s]"
     ]
    }
   ],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with trained_model:\n",
    "    trained_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trained_trace)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained_trace.get_values('difference in means')\n",
    "sd = np.std(samples)\n",
    "\n",
    "len(np.where((sd > samples) & (samples > -sd))[0]) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trained_trace, \n",
    "                  var_names=['difference in means', 'difference in variances', 'effect size'],\n",
    "                  ref_val=0, kind='hist', credible_interval=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_natural = bayes_model_df.loc[natural_sel & untrained_sel, 'position_id'].values.astype(int)\n",
    "err_natural = bayes_model_df.loc[natural_sel & untrained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "pos_synthetic = bayes_model_df.loc[synthetic_sel & untrained_sel, 'position_id'].values.astype(int)\n",
    "err_synthetic = bayes_model_df.loc[synthetic_sel & untrained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "data_dict = {'natural': {'x': pos_natural, 'y': err_natural},\n",
    "             'synthetic': {'x': pos_synthetic, 'y': err_synthetic}}\n",
    "\n",
    "untrained_model = build_binomial_model(data_dict)\n",
    "\n",
    "pm.model_to_graphviz(untrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with untrained_model:\n",
    "    untrained_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(untrained_trace)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "ax = pm.plot_posterior(untrained_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', \n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Natural - Synthetic; Untrained subjects', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between conditions, per stimulus type\n",
    "\n",
    "####  Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_trained = bayes_model_df.loc[natural_sel & trained_sel, 'subject'].values.astype(int)\n",
    "err_trained = bayes_model_df.loc[natural_sel & trained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "sub_untrained = bayes_model_df.loc[natural_sel & untrained_sel, 'subject'].values.astype(int)\n",
    "err_untrained = bayes_model_df.loc[natural_sel & untrained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "data_dict = {'trained': {'x': sub_trained, 'y': err_trained},\n",
    "             'untrained': {'x': sub_untrained, 'y': err_untrained}}\n",
    "\n",
    "natural_model = build_binomial_model(data_dict)\n",
    "\n",
    "pm.model_to_graphviz(natural_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with natural_model:\n",
    "    natural_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(natural_trace)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "ax = pm.plot_posterior(natural_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', \n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Trained - Untrained; Natural positions', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_trained = bayes_model_df.loc[synthetic_sel & trained_sel, 'subject'].values.astype(int)\n",
    "err_trained = bayes_model_df.loc[synthetic_sel & trained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "sub_untrained = bayes_model_df.loc[synthetic_sel & untrained_sel, 'subject'].values.astype(int)\n",
    "err_untrained = bayes_model_df.loc[synthetic_sel & untrained_sel, 'errors'].values.astype(int)\n",
    "\n",
    "data_dict = {'trained': {'x': sub_trained, 'y': err_trained},\n",
    "             'untrained': {'x': sub_untrained, 'y': err_untrained}}\n",
    "\n",
    "synthetic_model = build_binomial_model(data_dict)\n",
    "\n",
    "pm.model_to_graphviz(synthetic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kwargs = {'target_accept': .98}\n",
    "with synthetic_model:\n",
    "    synthetic_trace = pm.sample(16000, cores=4, tune=4000, nuts_kwargs=nuts_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(synthetic_trace)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "ax = pm.plot_posterior(untrained_trace, \n",
    "                       var_names=['difference in means'],\n",
    "                       ref_val=0, credible_interval=.95,\n",
    "                       kind='hist', \n",
    "                       figsize=(4, 3))\n",
    "plt.setp(ax, \n",
    "         title='Natural - Synthetic; Untrained subjects', \n",
    "         xlabel=r'$\\Delta$ error rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = untrained_trace.get_values('difference in means')\n",
    "\n",
    "len(np.where((-.01 < sample) & (sample < .01))[0]) / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample[sample < -.01]) / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample[sample > .01]) / len(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
