{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.utility_functions import *\n",
    "from lib.exp4 import *\n",
    "\n",
    "# Config\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tidy dataframe (produced in 4 Data Analysis and Exploration)\n",
    "tidy = pd.read_csv('./tidy_data.csv', index_col=0)\n",
    "tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_table = tidy.pivot_table(\n",
    "    index='Condition', \n",
    "    values=['Type I Errors', 'Type II Errors', 'Type III Errors'], \n",
    "    aggfunc=np.sum\n",
    ")\n",
    "\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_table = freq_table.copy()\n",
    "prob_table.loc['Naive'] = freq_table.loc['Naive'] / freq_table.loc['Naive'].sum()\n",
    "prob_table.loc['Trained'] = freq_table.loc['Trained'] / freq_table.loc['Trained'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(e | c=naive) = p(e | c=trained) = p(e) # null hypothesis for chisq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq, p, dof, ex = sts.chi2_contingency(freq_table)\n",
    "print('Chi-square test result: {:.2f}, p={:.4f}'.format(chisq, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 9), dpi=300)\n",
    "\n",
    "axes.bar(np.arange(3) - .175, prob_table.loc['Naive'], width=.3, edgecolor='white', label='Untrained')\n",
    "axes.bar(np.arange(3) + .175, prob_table.loc['Trained'], width=.3, edgecolor='white', label='Trained')\n",
    "axes.legend(loc=0)\n",
    "\n",
    "plt.setp(\n",
    "    axes, \n",
    "    ylabel='Error Probability', \n",
    "    xlabel='Error Type', xticks=[0, 1, 2], xticklabels=['Type I', 'Type II', 'Type III']\n",
    ")\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tidier data on error types and check out figures\n",
    "#    (for own edification)\n",
    "melted = pd.melt(\n",
    "    tidy, \n",
    "    id_vars=['Condition'],\n",
    "    value_vars=['Type I Errors', 'Type II Errors', 'Type III Errors'], \n",
    "    var_name='Error Type', value_name='Num Errors'\n",
    ")\n",
    "\n",
    "melted['Num Errors Dummy'] = melted['Num Errors']\n",
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tidy['Nume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g = sns.factorplot(\n",
    "    x='Error Type', y='Num Errors', hue='Condition', \n",
    "    data=melted, \n",
    "    kind='bar',\n",
    "    legend_out=True, size=8, aspect=16/9\n",
    ")\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = melted.pivot_table(\n",
    "    index='Num Errors', columns='Error Type', \n",
    "    values='Num Errors Dummy', \n",
    "    aggfunc=len\n",
    ")\n",
    "\n",
    "remelted = pd.melt(\n",
    "    pivoted, \n",
    "    value_vars=['Type I Errors', 'Type II Errors', 'Type III Errors'], \n",
    "    value_name='Count'\n",
    ")\n",
    "\n",
    "remelted['Num Errors'] = remelted.index.values % 16\n",
    "\n",
    "g = sns.factorplot(\n",
    "    x='Num Errors', y='Count', hue='Error Type', \n",
    "    data=remelted, \n",
    "    kind='bar', legend_out=True,\n",
    "    size=8, aspect=16/9\n",
    ")\n",
    "\n",
    "sns.despine(ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old\n",
    "\n",
    "The below was a communication mistake, looking at chisq over different error types x different number of occurrences of those errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy['Type I Error Dummies'] = tidy['Type I Errors']\n",
    "tidy['Type II Error Dummies'] = tidy['Type II Errors']\n",
    "tidy['Type III Error Dummies'] = tidy['Type III Errors']\n",
    "\n",
    "# Get number of observations at each variable level (number of errors)\n",
    "e1 = tidy.pivot_table(index='Type I Errors', values='Type I Error Dummies', aggfunc=len)\n",
    "e2 = tidy.pivot_table(index='Type II Errors', values='Type II Error Dummies', aggfunc=len)\n",
    "e3 = tidy.pivot_table(index='Type III Errors', values='Type III Error Dummies', aggfunc=len)\n",
    "\n",
    "# Create placeholder dataframe, add error types, and fill in nans with 0\n",
    "e = pd.DataFrame(index=e2.index.values, columns=['I', 'II', 'III'])\n",
    "e.loc[e1.index, 'I'] = e1['Type I Error Dummies']\n",
    "e.loc[e2.index, 'II'] = e2['Type II Error Dummies']\n",
    "e.loc[e3.index, 'III'] = e3['Type III Error Dummies']\n",
    "\n",
    "e.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data is missing. To work with the missing data, I treat errors >= 12 as a single bin. Chi-square test is senstive to binning choices, but here difference is so stark it hardly matters. Is there a principled way to deal with this circumstance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin observations of greater than or equal to 12 errors together\n",
    "e.loc[12, 'I'] += e.iloc[13:]['I'].sum()\n",
    "e.loc[12, 'II'] += e.iloc[13:]['II'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy ChiSq test\n",
    "chisq, p, dof, ex = sts.chi2_contingency(e.iloc[1:12])\n",
    "print('Chi-square test result: {:.2f}, p={:.4f}'.format(chisq, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tidier data on error types and check out figures\n",
    "#    (for own edification)\n",
    "melted = pd.melt(tidy, value_vars=['Type I Errors', 'Type II Errors', 'Type III Errors'], var_name='Error Type', value_name='Num Errors')\n",
    "\n",
    "melted['Num Errors Dummy'] = melted['Num Errors']\n",
    "\n",
    "pivoted = melted.pivot_table(\n",
    "    index='Num Errors', columns='Error Type', \n",
    "    values='Num Errors Dummy', \n",
    "    aggfunc=len\n",
    ")\n",
    "\n",
    "remelted = pd.melt(\n",
    "    pivoted, \n",
    "    value_vars=['Type I Errors', 'Type II Errors', 'Type III Errors'], \n",
    "    value_name='Count'\n",
    ")\n",
    "\n",
    "remelted['Num Errors'] = remelted.index.values % 16\n",
    "\n",
    "g = sns.factorplot(\n",
    "    x='Num Errors', y='Count', hue='Error Type', \n",
    "    data=remelted, \n",
    "    kind='bar', legend_out=True,\n",
    "    size=8, aspect=16/9\n",
    ")\n",
    "\n",
    "sns.despine(ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "One alternative to Chi-Sq test could be Kolmogorov-Smirnov test. But I think raw data violate continuous assumption of KS test, as data are relatively low count values in [0, 15]; Chi-Sq is probably more natural choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ks_2samp(tidy['Type II Errors'], tidy['Type III Errors'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
