{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from lib.utility_functions import *\n",
    "from lib.exp4 import *\n",
    "\n",
    "# Config\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.read_csv('./tidy_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are subjects more likely to reproduce some features than others? *\n",
    "# Are trained subjects more likely to reproduce game set features? ***\n",
    "# Probability of missing a piece that is / is not part of a feature (or by # of features piece is part of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hstarts = [i for row in range(4) for i in range(9*row, 9*row + 6, 1)]\n",
    "vstarts = list(range(9))\n",
    "ddstarts = list(range(6))\n",
    "dustarts = list(range(4, 9))\n",
    "\n",
    "\n",
    "def _add_position_strings(bp, wp):\n",
    "    return ''.join([str(int(b) + int(w)) for b, w in zip(bp, wp)])\n",
    "\n",
    "\n",
    "def _count_feature(bp, wp, feature):\n",
    "    \n",
    "    # Get the overall occupancy of position\n",
    "    p = _add_position_strings(bp, wp)\n",
    "\n",
    "    # Initialize count matrices\n",
    "    bcounts = np.zeros(36, dtype=np.uint8)\n",
    "    wcounts = np.zeros(36, dtype=np.uint8)\n",
    "    \n",
    "    # Helper function to detect matchs in different orientations\n",
    "    def _orient_count(start, increment):\n",
    "    \n",
    "        end = start + 4 * increment\n",
    "\n",
    "        for orientation in [1, -1]:\n",
    "            total_match = p[start:end:increment] == feature[::orientation]\n",
    "\n",
    "            if not total_match:\n",
    "                # If the complete position is not the same as feature,\n",
    "                #    it means that some locations that should have been \n",
    "                #    empty were not, so just continue\n",
    "                continue\n",
    "                \n",
    "            black_match = bp[start:end:increment] == feature[::orientation]\n",
    "\n",
    "            if black_match:\n",
    "                bcounts[start:end:increment] += 1\n",
    "\n",
    "                # If we found a black_match, no need to check white position\n",
    "                break\n",
    "\n",
    "            white_match = wp[start:end:increment] == feature[::orientation]\n",
    "\n",
    "            if white_match:\n",
    "                wcounts[start:end:increment] += 1\n",
    "\n",
    "        return None\n",
    "    \n",
    "    # For every horizontal starting value\n",
    "    for start in hstarts:\n",
    "        _orient_count(start, 1)\n",
    "          \n",
    "    # Etc\n",
    "    for start in vstarts:\n",
    "        _orient_count(start, 9)\n",
    "            \n",
    "    for start in dustarts:\n",
    "        _orient_count(start, 8)\n",
    "            \n",
    "    for start in ddstarts:\n",
    "        _orient_count(start, 10)\n",
    "             \n",
    "    return bcounts + wcounts\n",
    "\n",
    "\n",
    "def count_all_features(row):\n",
    "    features = ['1100', '1010', '1001', '1110', '1101', '1111']\n",
    "    bp = row['Black Position']\n",
    "    wp = row['White Position']\n",
    "    \n",
    "    output_dict = {}\n",
    "    for feature in features:\n",
    "        count = _count_feature(bp, wp, feature)\n",
    "        \n",
    "        output_dict[feature] = count\n",
    "        \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _detect_type_2_error(bi, bf, wi, wf):\n",
    "    original_empty = ((bf == '0') and (wf == '0')) \n",
    "    final_not_empty = ((bi == '1') or (wi == '1'))\n",
    "    \n",
    "    return int(original_empty and final_not_empty)\n",
    "\n",
    "def _detect_type_3_error(bi, bf, wi, wf):\n",
    "    b2w = ((bi == '1') and (wf == '1'))\n",
    "    w2b = ((wi == '1') and (bf == '1'))\n",
    "    \n",
    "    return int(b2w or w2b)\n",
    "\n",
    "def count_all_errors(row):\n",
    "    bpi = row['Black Position']\n",
    "    bpf = row['Black Position (final)']\n",
    "    \n",
    "    wpi = row['White Position']\n",
    "    wpf = row['White Position (final)']\n",
    "    \n",
    "    \n",
    "    type_2_errors = [\n",
    "        _detect_type_2_error(bi, bf, wi, wf)\n",
    "        for bi, bf, wi, wf in zip(bpi, bpf, wpi, wpf)\n",
    "    ]\n",
    "    \n",
    "    type_3_errors = [\n",
    "        _detect_type_3_error(bi, bf, wi, wf)\n",
    "        for bi, bf, wi, wf in zip(bpi, bpf, wpi, wpf)\n",
    "    ]\n",
    "    \n",
    "    return {'Type 2': type_2_errors, 'Type 3': type_3_errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count_df = pd.DataFrame(tidy.apply(count_all_features, axis=1).tolist())\n",
    "error_df = pd.DataFrame(tidy.apply(count_all_errors, axis=1).tolist())\n",
    "sum_df = pd.concat([error_df, feature_count_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_features(row):\n",
    "    \n",
    "    counts = np.zeros(36, dtype=np.uint8)\n",
    "    \n",
    "    for name in row.index:\n",
    "        if 'Type' not in name:\n",
    "\n",
    "            counts += np.stack(row[name])\n",
    "                \n",
    "    return counts.tolist()\n",
    "\n",
    "sum_df['all'] = sum_df.apply(sum_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_errors_by_num_features(row, error_type):\n",
    "    type2 = row[error_type]\n",
    "    feats = row['all']\n",
    "    \n",
    "    counts = {}\n",
    "    for i, f in enumerate(feats):\n",
    "        if f not in counts.keys():\n",
    "            counts[f] = 0\n",
    "            \n",
    "        counts[f] += type2[i]\n",
    "        \n",
    "    return counts\n",
    "\n",
    "\n",
    "def bin_errors_type2(row):\n",
    "    return bin_errors_by_num_features(row, 'Type 2')\n",
    "\n",
    "\n",
    "def bin_errors_type3(row):\n",
    "    return bin_errors_by_num_features(row, 'Type 3')\n",
    "\n",
    "\n",
    "def bin_features(row):\n",
    "    idx = row.name\n",
    "    bp = tidy.iloc[idx]['Black Position']\n",
    "    wp = tidy.iloc[idx]['White Position']\n",
    "    p = _add_position_strings(bp, wp)\n",
    "    p = list(map(int, p))\n",
    "    \n",
    "    feats = row['all']\n",
    "    \n",
    "    counts = {}\n",
    "    for i, f in enumerate(feats):\n",
    "        if f not in counts.keys():\n",
    "            counts[f] = 0\n",
    "            \n",
    "        counts[f] += p[i]\n",
    "        \n",
    "    return counts\n",
    "    \n",
    "\n",
    "type2_counts = pd.DataFrame(sum_df.apply(bin_errors_type2, axis=1).tolist()).fillna(0)\n",
    "type3_counts = pd.DataFrame(sum_df.apply(bin_errors_type3, axis=1).tolist()).fillna(0)\n",
    "feature_counts = pd.DataFrame(sum_df.apply(bin_features, axis=1).tolist()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman: # features, # errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.258431\n",
       "1    0.256140\n",
       "2    0.261877\n",
       "3    0.246600\n",
       "4    0.146491\n",
       "5    0.032895\n",
       "6    0.131579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_counts.sum(axis=0) / feature_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Type 3</th>\n",
       "      <th>1001</th>\n",
       "      <th>1010</th>\n",
       "      <th>1100</th>\n",
       "      <th>1101</th>\n",
       "      <th>1110</th>\n",
       "      <th>1111</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, ...</td>\n",
       "      <td>[1, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 2, 2, 2, 4, 2, 1, 0, 0, 0, 1, 2, 2, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 2, 3, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Type 2  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              Type 3  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                1001  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                1010  \\\n",
       "0  [0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 1, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "\n",
       "                                                1100  \\\n",
       "0  [1, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "\n",
       "                                                1101  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                1110  \\\n",
       "0  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                1111  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 all  \n",
       "0  [1, 2, 2, 2, 4, 2, 1, 0, 0, 0, 1, 2, 2, 3, 2, ...  \n",
       "1  [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...  \n",
       "2  [1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, ...  \n",
       "4  [0, 0, 1, 2, 3, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist2 = type2_counts.sum(axis=0) / feature_counts.sum(axis=0)\n",
    "# for Type II/III errors, number of possible errors is limited by number of pieces\n",
    "# so feature_counts is for each position the number of pieces\n",
    "# with X features present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist3 = type3_counts.sum(axis=0) / feature_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.8571428571428572, pvalue=0.004170568509644835)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.ks_2samp(dist2.values, dist3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number of features, count the number of Type 2 errors\n",
    "\n",
    "type2 = sum_df.iloc[0]['Type 2']\n",
    "feats = sum_df.iloc[0]['all']\n",
    "\n",
    "print(type2)\n",
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_2_error_counts = np.stack(sum_df['Type 2'].values)\n",
    "total_feature_counts = np.stack(sum_df['all'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_count_against_num_features(row, error_type):\n",
    "    fc = np.stack(row['all']).astype(np.uint8)\n",
    "    ec = np.stack(row[error_type]).astype(np.uint8)\n",
    "    \n",
    "    pcount = {\n",
    "        k: np.sum(ec[fc == k])\n",
    "        for k in range(fc.max()+1)\n",
    "    }\n",
    "    \n",
    "    return pcount\n",
    "\n",
    "\n",
    "def error2_count_against_num_features(row):\n",
    "    return error_count_against_num_features(row, 'Type 2')\n",
    "    \n",
    "\n",
    "def error3_count_against_num_features(row):\n",
    "    return error_count_against_num_features(row, 'Type 3')\n",
    "\n",
    "\n",
    "def instance_count_against_num_features(row):\n",
    "    fc = np.stack(row['all']).astype(np.uint8)\n",
    "    \n",
    "    pcount = {\n",
    "        k: np.sum(fc == k)\n",
    "        for k in range(fc.max()+1)\n",
    "    }\n",
    "    \n",
    "    return pcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_errors_by_feature_count = pd.DataFrame(\n",
    "    sum_df.apply(error2_count_against_num_features, axis=1).tolist()\n",
    ").fillna(0)\n",
    "\n",
    "type3_errors_by_feature_count = pd.DataFrame(\n",
    "    sum_df.apply(error3_count_against_num_features, axis=1).tolist()\n",
    ").fillna(0)\n",
    "\n",
    "instances_by_feature_count = pd.DataFrame(\n",
    "    sum_df.apply(instance_count_against_num_features, axis=1).tolist()\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type2_j_num_features = type2_errors_by_feature_count.sum(axis=0) / tidy['Num Pieces'].sum()\n",
    "p_num_features = instances_by_feature_count.sum(axis=0) / instances_by_feature_count.sum()\n",
    "\n",
    "err2_dist = p_type2_j_num_features / p_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type3_j_num_features = type3_errors_by_feature_count.sum(axis=0) / tidy['Num Pieces'].sum()\n",
    "\n",
    "err3_dist = p_type3_j_num_features / p_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err3_dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].bar(np.arange(7), err2_dist)\n",
    "axes[1].bar(np.arange(7), err3_dist)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_tidy = pd.melt(\n",
    "    type2_errors_by_feature_count,\n",
    "    var_name='Num Features', value_name='Error Count'\n",
    ")\n",
    "\n",
    "err2_tidy['dummy'] = err2_tidy['Error Count']\n",
    "\n",
    "err2_sum_piv = err2_tidy.pivot_table(\n",
    "    index='Num Features', values='Error Count', \n",
    "    aggfunc=np.sum\n",
    ")\n",
    "\n",
    "err2_len_piv = err2_tidy.pivot_table(\n",
    "    index='Num Features', values='Error Count',\n",
    "    aggfunc=len\n",
    ")\n",
    "\n",
    "err2_sum_piv / err2_len_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_len_piv = err2_tidy.pivot_table(\n",
    "    index='Num Features', columns='Error Count', values='dummy',\n",
    "    aggfunc=len\n",
    ")\n",
    "\n",
    "err2_len_piv.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_sum_piv = err2_tidy.pivot_table(\n",
    "    index='Num Features', columns='Error Count', values='dummy',\n",
    "    aggfunc=np.sum\n",
    ")\n",
    "\n",
    "p_num_err2_j_num_feat = err2_sum_piv.fillna(0) / err2_tidy['Error Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_feat = instances_by_feature_count.sum() / instances_by_feature_count.sum().sum()\n",
    "p_num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_feat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_err2_j_num_feat.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_err2_c_num_feat = p_num_err2_j_num_feat.copy()\n",
    "p_num_err2_c_num_feat.loc[:, :] = p_num_err2_j_num_feat.values / p_num_feat.values[:, np.newaxis]\n",
    "p_num_err2_c_num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_err2_c_num_feat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2_tidy['Error Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "\n",
    "\n",
    "err3_tidy = pd.melt(\n",
    "    type3_errors_by_feature_count / instances_by_feature_count, \n",
    "    var_name='Num Features', value_name='Error Prob'\n",
    ")\n",
    "\n",
    "sns.factorplot(\n",
    "    x='Num Features', y='Error Prob', data=err2_tidy, ax=axes[0],\n",
    "    kind='bar', ci=95, n_boot=1000, color='grey'\n",
    ")\n",
    "\n",
    "sns.factorplot(\n",
    "    x='Num Features', y='Error Prob', data=err3_tidy, ax=axes[1],\n",
    "    kind='bar', ci=95, n_boot=1000, color='grey'\n",
    ")\n",
    "\n",
    "\n",
    "plt.setp(axes[0], ylabel='Type 2 Error Probability')\n",
    "plt.setp(axes[1], ylabel='Type 3 Error Probability')\n",
    "\n",
    "sns.despine(ax=axes[0])\n",
    "sns.despine(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy['Type III Errors'].sum() / tidy['Num Pieces'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dustarts\n",
    "\n",
    "_idx = list(range(36))[8:40:8]\n",
    "\n",
    "_l = np.zeros(36)\n",
    "_l[_idx] = 1\n",
    "_l.reshape((4, 9))\n",
    "\n",
    "print(list(range(36))[5:45:10])\n",
    "\n",
    "row = sum_df.iloc[0]\n",
    "\n",
    "row.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_string = tidy.iloc[0]['Black Position']\n",
    "feature = '1010'\n",
    "start, end = 0, 4\n",
    "\n",
    "print(position_string)\n",
    "position_string[start:end] == feature\n",
    "position_string[start:end:9] == feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = tidy.iloc[0]\n",
    "bpi = row['Black Position']\n",
    "bpf = row['Black Position (final)']\n",
    "wpi = row['White Position']\n",
    "wpf = row['White Position (final)']\n",
    "\n",
    "error_counts = errors(row)\n",
    "print(''.join([str(i) for i in error_counts['Type 2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = ''.join([str(int(b) + int(w)) for b, w in zip(bpi, wpi)])\n",
    "final = ''.join([str(int(b) + int(w)) for b, w in zip(bpf, wpf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(initial)\n",
    "print(''.join([str(i) for i in error_counts['Type 2']]))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bpi)\n",
    "print(wpf)\n",
    "print(''.join([str(i) for i in error_counts['Type 3']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "position_string[start:start+28:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_string_to_array(position_string):\n",
    "    position_list = np.stack([int(c) for c in position_string]).reshape((4, 9))\n",
    "    \n",
    "    return position_list\n",
    "\n",
    "black_positions = np.stack(tidy['Black Position'].map(position_string_to_array).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = np.array([1, 1, 0, 0])\n",
    "feature2 = np.array([1, 0, 1, 0])\n",
    "feature3 = np.array([1, 0, 0, 1])\n",
    "feature4 = np.array([1, 1, 1, 0])\n",
    "feature5 = np.array([1, 1, 0, 1])\n",
    "feature6 = np.array([1, 1, 1, 1])\n",
    "\n",
    "def count_feature_occurrences(positions, feature):\n",
    "    counts = np.zeros_like(positions)\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_string = tidy.iloc[0]['Black Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.stack([c for c in position_string]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.zeros_like(position)\n",
    "start, end = 0, 4\n",
    "all(position[np.arange(start, end, 1)] == feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature1\n",
    "convolve2d(black_positions[0], feature[np.newaxis, :], mode='same') == feature.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
